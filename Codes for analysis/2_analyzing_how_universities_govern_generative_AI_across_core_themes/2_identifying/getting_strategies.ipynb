{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d742df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from identifier import *\n",
    "# Load the JSON file\n",
    "with open(\"../2_deciphering_strategies/analyses.json\", \"r\") as file:\n",
    "    query_answers = json.load(file)\n",
    "\n",
    "for i in (list(query_answers.keys())):\n",
    "    query_answers[i]=dict(query_answers[i])\n",
    "\n",
    "    # Loop through each outer key in query_answers and modify the inner dictionary\n",
    "for outer_key, inner_dict in query_answers.items():\n",
    "    # Filter out entries in the inner dictionary that start with the specified phrase\n",
    "    inner_dict = {k: v for k, v in inner_dict.items() if not v.lower().startswith(\"no content could be found\")}\n",
    "    query_answers[outer_key] = inner_dict  # Update the outer dictionary with the cleaned inner dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cbd4176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6bce9c69a9540e19de0497141efef0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df69b51f25274acdaced5ce69dc86fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK FAILED: FAIL\n",
      "\n",
      "1. **Prohibition of Unauthorized AI Use in Assignments**: The analysis claims that Johns Hopkins University prohibits AI-generated content in assignments, which aligns with the provided summary. However, the summary does not explicitly mention the University of California at Berkeley or the University of Michigan--Ann Arbor as having strict prohibitions, which may not fully support the claim.\n",
      "\n",
      "2. **Requirement to Disclose AI Tool Usage**: The analysis states that the University of Washington requires disclosure of AI tool usage, which is supported by the summary. However, the California Institute of Technology's inclusion is questionable as the summary emphasizes disclosure but does not explicitly state a requirement for students to disclose AI tool usage.\n",
      "\n",
      "3. **Instructor-Defined AI Usage Guidelines**: The analysis includes the University of Florida, University of Chicago, and Vanderbilt University as examples. The summaries for these institutions do mention instructor-defined policies, but the analysis does not clarify that these policies may vary significantly between courses.\n",
      "\n",
      "4. **Emphasis on Academic Integrity Education**: The analysis includes the University of Maryland, University of California, San Diego, and University of Virginia. The summaries do mention academic integrity education, but the analysis does not specify how these institutions uniquely approach this education in the context of AI.\n",
      "\n",
      "5. **Consequences for Misrepresentation of AI Work**: The analysis includes Georgetown University, Princeton University, and Northwestern University. The summaries do mention consequences for misrepresentation, but the analysis does not clarify that these consequences may vary by instructor or course.\n",
      "\n",
      "6. **Encouragement of Open Dialogue on AI Use**: The analysis includes Columbia University, Carnegie Mellon University, and Yale University. The summaries do mention the importance of communication regarding AI use, but the analysis does not specify how these institutions uniquely foster open dialogue.\n",
      "\n",
      "Overall, while the analysis captures some accurate elements, it lacks specificity and clarity in how the examples align with the institutions' actual policies, leading to inaccuracies in the representation of the policies.\n",
      "HALLUCINATION CHECK FAILED: FAIL\n",
      "\n",
      "1. **Prohibition of Unauthorized AI Use in Assignments**: The analysis states that Johns Hopkins University prohibits AI-generated content in assignments, which aligns with the summary. However, it does not mention the specific context of proctored exams or quizzes, which is included in the summary.\n",
      "\n",
      "2. **Requirement to Disclose AI Tool Usage**: The analysis claims that the University of Washington requires students to disclose AI tool usage, which is consistent with the summary. However, it does not mention the varying policies among instructors, which is a significant aspect of the summary.\n",
      "\n",
      "3. **Instructor-Defined AI Usage Guidelines**: The analysis states that the University of Florida encourages instructors to define AI usage policies, which is accurate. However, it does not capture the emphasis on educating students about responsible AI practices, which is part of the summary.\n",
      "\n",
      "4. **Emphasis on Academic Integrity Education**: The analysis mentions the University of Maryland's focus on academic integrity education, which is accurate. However, it does not reflect the specific examples of permitted or prohibited AI tools mentioned in the summary.\n",
      "\n",
      "5. **Consequences for Misrepresentation of AI Work**: The analysis states that Georgetown University defines presenting AI-generated content as plagiarism, which is accurate. However, it does not mention the requirement to quote and cite sources, which is a key part of the summary.\n",
      "\n",
      "6. **Encouragement of Open Dialogue on AI Use**: The analysis claims that Columbia University promotes open discussions about AI use, which is consistent with the summary. However, it does not mention the importance of understanding and adhering to academic integrity standards, which is highlighted in the summary.\n",
      "\n",
      "Overall, while there are some accurate points, the analysis fails to capture significant details and nuances from the summaries, leading to a misrepresentation of the policies.\n",
      "TOO MANY ITERATIONS OF HALLUCINATION IDENTIFIED, REDOING ANALYSIS!\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK FAILED: FAIL\n",
      "\n",
      "1. **Prohibition of Unauthorized AI Use**: The analysis claims that the University of Georgia, Johns Hopkins University, and University of California, Santa Barbara prohibit unauthorized AI use. However, the summary for the University of Georgia does align with this policy, while the summaries for Johns Hopkins University and University of California, Santa Barbara do not explicitly state a prohibition on unauthorized AI use as described.\n",
      "\n",
      "2. **Requirement for Proper Attribution**: The analysis lists the University of Chicago, University of Michigan--Ann Arbor, and University of California, Davis as examples. The summary for University of California, Davis aligns with this policy, but the summaries for University of Chicago and University of Michigan--Ann Arbor do not clearly emphasize a requirement for proper attribution as described.\n",
      "\n",
      "3. **Instructor Discretion on AI Use**: The analysis cites California Institute of Technology, University of Southern California, and New York University. The summary for University of Southern California aligns with this policy, but the summaries for California Institute of Technology and New York University do not clearly indicate that instructors have discretion over AI use.\n",
      "\n",
      "4. **Clear Communication of AI Policies**: The analysis includes Harvard University, University of Wisconsin Madison, and University of Florida. The summary for University of Florida aligns with this policy, but the summaries for Harvard University and University of Wisconsin Madison do not clearly emphasize the communication of AI policies as described.\n",
      "\n",
      "5. **Consequences for Misrepresentation**: The analysis lists Princeton University, University of Notre Dame, and University of Rochester. The summary for University of Rochester aligns with this policy, but the summaries for Princeton University and University of Notre Dame do not clearly state consequences for misrepresentation as described.\n",
      "\n",
      "6. **Educational Approach to AI Ethics**: The analysis cites University of Illinois Urbana-Champaign, University of Maryland, and University of Florida. The summary for University of Florida aligns with this policy, but the summaries for University of Illinois Urbana-Champaign and University of Maryland do not clearly emphasize an educational approach to AI ethics as described.\n",
      "\n",
      "Overall, the examples provided in the analysis do not consistently align with the actual policies of the institutions as summarized, leading to inaccuracies in the analysis.\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK FAILED: FAIL\n",
      "\n",
      "1. **Prohibition of Unauthorized AI Use in Academic Work**: The analysis cites the University of California at Berkeley, University of Texas at Austin, Stanford University, University of Georgia, and University of Michigan--Ann Arbor as examples. However, the summaries indicate that while UC Berkeley and UGA have strict prohibitions, the summaries for the other institutions do not explicitly confirm a strict prohibition as described.\n",
      "\n",
      "2. **Requirement to Cite AI-Generated Content**: The analysis lists the University of California at Los Angeles, University of Washington, University of Chicago, University of California, Davis, and Northwestern University. The summaries for these institutions do mention citation requirements, but the specific phrasing and emphasis on citation as a requirement may not align perfectly with the analysis.\n",
      "\n",
      "3. **Instructor Discretion on AI Use**: The analysis includes University of Southern California, Vanderbilt University, University of Pennsylvania, Duke University, and University of North Carolina at Chapel Hill. The summaries do indicate instructor discretion, but the analysis may not fully capture the nuances of how this discretion is applied across these institutions.\n",
      "\n",
      "4. **Encouragement of Student Consultation with Instructors**: The analysis cites Texas A&M University, Massachusetts Institute of Technology, University of Maryland, University of Virginia, and University of Florida. The summaries do suggest encouragement for consultation, but the analysis may not accurately reflect the specific policies or the emphasis placed on this aspect.\n",
      "\n",
      "5. **Clear Communication of AI Policies in Syllabi**: The analysis lists Harvard University, California Institute of Technology, University of California, Santa Barbara, Johns Hopkins University, and Rice University. The summaries indicate a focus on clear communication, but the specific phrasing and emphasis may not align perfectly with the analysis.\n",
      "\n",
      "Overall, while there are elements of truth in the analysis, the inaccuracies in the alignment of institutions with their actual policies lead to a conclusion of significant discrepancies.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HALLUCINATION CHECK FAILED: FAIL\n",
      "\n",
      "- The analysis claims that the University of California at Berkeley prohibits the use of AI tools in exam situations and considers any use that constitutes plagiarism a violation of the honor code. However, the summary indicates that while AI use is prohibited in exams, it does not explicitly state that all use is considered plagiarism, which is a significant misrepresentation.\n",
      "  \n",
      "- The analysis states that the University of Georgia strictly prohibits unauthorized AI use in academic work, which aligns with the summary. However, it does not mention that instructors can define acceptable use, which is a critical aspect of the policy.\n",
      "\n",
      "- The analysis includes the University of California, Los Angeles as requiring proper citation of AI-generated content, which is accurate. However, it does not mention the encouragement for students to consult with instructors regarding acceptable use, which is a significant part of the policy.\n",
      "\n",
      "- The analysis claims that the University of Michigan--Ann Arbor emphasizes the need to acknowledge generative AI as a source to avoid plagiarism, which is accurate. However, it does not mention the encouragement for instructors to define clear course policies on AI use, which is a significant aspect of the policy.\n",
      "\n",
      "- The analysis includes the University of Southern California as allowing instructors to set their own policies regarding AI use, which is accurate. However, it does not mention the requirement for students to properly cite AI-generated material, which is a significant aspect of the policy.\n",
      "\n",
      "- The analysis states that the University of Chicago considers using AI-generated content without proper attribution as plagiarism, which is accurate. However, it does not mention the discretion given to instructors to set their own rules regarding AI tools, which is a significant aspect of the policy.\n",
      "\n",
      "- The analysis claims that the University of Virginia emphasizes the importance of using AI tools responsibly, which is accurate. However, it does not mention the encouragement for students to consult their instructors about permissible uses of AI, which is a significant aspect of the policy.\n",
      "\n",
      "- The analysis includes the University of Florida as emphasizing the importance of maintaining academic integrity in the context of AI use, which is accurate. However, it does not mention the encouragement for faculty to define clear course policies regarding acceptable use of generative AI, which is a significant aspect of the policy.\n",
      "\n",
      "- The analysis states that the University of Pennsylvania does not have a standardized policy on AI use, which is accurate. However, it does not mention the prohibition against submitting AI-generated work as their own without proper attribution, which is a significant aspect of the policy.\n",
      "\n",
      "- The analysis includes the University of California, Santa Barbara as prohibiting unauthorized use of AI for completing coursework, which is accurate. However, it does not mention the requirement for students to ensure that any materials submitted represent their own efforts unless explicitly permitted by their instructor, which is a significant aspect of the policy.\n",
      "\n",
      "- The analysis claims that the University of Chicago considers using AI-generated content without proper attribution as plagiarism, which is accurate. However, it does not mention the discretion given to instructors to set their own rules regarding AI tools, which is a significant aspect of the policy.\n",
      "\n",
      "Overall, the analysis contains significant inaccuracies and misrepresentations regarding the policies of the institutions listed.\n",
      "TOO MANY ITERATIONS OF HALLUCINATION IDENTIFIED, REDOING ANALYSIS!\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7febf5fec3014b6082aff7628c72464f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK FAILED: FAIL\n",
      "\n",
      "1. **Policy: Clear Communication of AI Use in Syllabus**  \n",
      "   - **Example:** University of California, Los Angeles - The summary indicates that instructors are encouraged to clarify expectations regarding acceptable uses of AI tools, which aligns with the policy description. However, the specific mention of \"detailing what is permissible and what is not\" is not explicitly stated in the summary.\n",
      "\n",
      "2. **Policy: Early and Ongoing Discussions about AI Policies**  \n",
      "   - **Example:** University of Wisconsin Madison - The summary supports the idea of ongoing discussions about AI use, but it does not explicitly mention the need for these discussions to be revisited throughout the course as stated in the policy description.\n",
      "\n",
      "3. **Policy: Integration of AI into Assignments with Clear Guidelines**  \n",
      "   - **Example:** Columbia University - The summary supports the idea of incorporating AI into assignments, but it does not explicitly mention the need for clear guidelines on how these tools should be used, which is a key aspect of the policy description.\n",
      "\n",
      "4. **Policy: Emphasis on Academic Integrity and Ethical Use of AI**  \n",
      "   - **Example:** Yale University - The summary supports the idea of communicating academic integrity in relation to AI use, but it does not explicitly mention the need for educational sessions and discussions about ethical considerations, which is a key aspect of the policy description.\n",
      "\n",
      "5. **Policy: Tailored AI Policies Based on Course Objectives**  \n",
      "   - **Example:** University of Chicago - The summary supports the idea of tailoring AI policies to course objectives, but it does not explicitly mention the need for policies to align with pedagogical goals, which is a key aspect of the policy description.\n",
      "\n",
      "6. **Policy: Transparency in AI Tool Usage and Documentation**  \n",
      "   - **Example:** University of Southern California - The summary supports the idea of requiring students to document their use of AI tools, but it does not explicitly mention the need for proper citations and the context in which AI was utilized, which is a key aspect of the policy description.\n",
      "HALLUCINATION CHECK FAILED: FAIL\n",
      "\n",
      "1. **Policy: Clear Communication of AI Use in Syllabus** - The analysis claims that multiple universities, including University of California, Los Angeles and University of Michigan--Ann Arbor, have this policy. However, the summaries indicate that while these institutions emphasize clear communication, they also include additional elements such as discussions about AI use and academic integrity, which are not captured in the analysis.\n",
      "\n",
      "2. **Policy: Early and Ongoing Discussions about AI Policies** - The analysis lists several universities, including Harvard University and University of Wisconsin Madison, as having this policy. However, the summaries suggest that while these institutions encourage discussions, they also emphasize the importance of clear guidelines in the syllabus, which is not reflected in the analysis.\n",
      "\n",
      "3. **Policy: Integration of AI into Assignments with Clear Guidelines** - The analysis includes examples like Columbia University and Stanford University, but the summaries indicate that these institutions focus on clear expectations and ethical considerations rather than solely on integration into assignments.\n",
      "\n",
      "4. **Policy: Emphasis on Academic Integrity and Ethical Use of AI** - The analysis lists institutions like Yale University and Georgetown University, but the summaries show that these universities also emphasize the need for clear communication of AI policies, which is not mentioned in the analysis.\n",
      "\n",
      "5. **Policy: Tailored AI Policies Based on Course Objectives** - The analysis claims that institutions like University of Chicago and California Institute of Technology have this policy. However, the summaries indicate that these institutions also focus on clear communication and ethical considerations, which are not captured in the analysis.\n",
      "\n",
      "6. **Policy: Transparency in AI Tool Usage and Documentation** - The analysis includes examples like University of Southern California and Carnegie Mellon University, but the summaries indicate that these institutions also emphasize the importance of clear guidelines and academic integrity, which are not reflected in the analysis.\n",
      "\n",
      "Overall, the analysis fails to accurately represent the nuances and additional elements present in the summarized policies of the institutions listed.\n",
      "TOO MANY ITERATIONS OF HALLUCINATION IDENTIFIED, REDOING ANALYSIS!\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dad52e74add4fb6970988ec6f0cfe82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK FAILED: FAIL\n",
      "\n",
      "1. **Prohibition of Sensitive Data Input**: The analysis lists the University of Michigan--Ann Arbor, University of California, Davis, University of Florida, and Harvard University as examples. However, the summaries indicate that the University of Michigan advises against using sensitive information but does not explicitly prohibit it in the same manner as described. The University of Florida has similar guidelines but does not align perfectly with the description of a strict prohibition. Harvard's summary aligns with the policy, but the other two do not fully match the analysis.\n",
      "\n",
      "2. **Data Classification and Risk Assessment**: The analysis includes the University of Wisconsin Madison and University of Chicago as examples. The summary for the University of Wisconsin Madison mentions policies that classify data and require internal reviews, which aligns with the analysis. However, the University of Chicago's summary does not mention a classification system or risk assessment process, which is a significant deviation.\n",
      "\n",
      "3. **Mandatory Review and Approval Processes**: The analysis lists the University of California at Irvine, Dartmouth College, University of Notre Dame, and Princeton University. The summaries for the University of California at Irvine and Dartmouth College align with the analysis, but the University of Notre Dame's summary does not explicitly mention a mandatory review process, and Princeton's summary focuses more on data privacy without detailing a review process.\n",
      "\n",
      "4. **User Responsibility and Ethical Considerations**: The analysis includes Vanderbilt University, University of Pennsylvania, University of Southern California, and Texas A&M University. The summaries for these institutions do mention user responsibility, but the specifics of ethical considerations vary, particularly for the University of Southern California, which emphasizes caution but does not explicitly mention user responsibility in the same way.\n",
      "\n",
      "5. **Vendor Risk Assessment for AI Tools**: The analysis lists the University of California, San Diego, UC Berkeley, University of California, Los Angeles, and Lehigh University. The summaries for UC San Diego and Lehigh University align with the analysis, but UC Berkeley's summary indicates a lack of agreements with generative AI companies, which does not support the idea of a vendor risk assessment.\n",
      "\n",
      "6. **Explicit Consent and Anonymization**: The analysis includes the University of Virginia, Yale University, University of Maryland, and University of Rochester. The summaries for these institutions do mention consent and anonymization, but the specifics vary, particularly for the University of Maryland, which does not explicitly mention consent in the same way as described in the analysis.\n",
      "\n",
      "Overall, the analysis contains significant inaccuracies regarding the alignment of institutions with the described policies.\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK FAILED: FAIL\n",
      "\n",
      "1. **Prohibition of Sensitive Data Input into AI Tools**: The analysis lists the University of Southern California, University of California, San Diego, Harvard University, and University of Michigan--Ann Arbor as examples. However, the summaries indicate that while USC and UCSD have guidelines against using sensitive data, they do not explicitly prohibit it in the same manner as described. Harvard and Michigan have similar cautions but do not align perfectly with the strict prohibition stated in the analysis.\n",
      "\n",
      "2. **Requirement for Data Classification and Risk Assessment**: The analysis includes the University of North Carolina at Chapel Hill and Northwestern University as examples. However, the summaries indicate that UNC requires risk assessments but does not explicitly mention a classification process, and Northwestern's summary does not clearly state a requirement for risk assessments.\n",
      "\n",
      "3. **Mandatory Use of Approved AI Tools**: The analysis lists Stanford University and University of Chicago as examples. The summaries indicate that while both institutions advise against using unapproved tools, they do not explicitly mandate the use of only approved tools as described in the analysis.\n",
      "\n",
      "4. **User Education and Consent Requirements**: The analysis includes the University of California, Los Angeles and Princeton University. However, the summaries do not clearly indicate that these institutions have mandatory consent requirements as described.\n",
      "\n",
      "5. **Prohibition of Data Sharing with Third-Party AI Vendors**: The analysis includes Texas A&M University and University of Pennsylvania. The summaries do not explicitly state a prohibition on data sharing with third-party vendors as described in the analysis.\n",
      "\n",
      "Overall, the examples provided in the analysis do not consistently align with the actual policies summarized for each institution, leading to significant inaccuracies.\n",
      "HALLUCINATION CHECK FAILED: FAIL\n",
      "\n",
      "1. **Prohibition of Sensitive Data Input into AI Tools**: The analysis lists several universities, including the University of Southern California and Harvard University, which do have policies against inputting sensitive data into AI tools. However, the specific details of their policies may not align perfectly with the description provided in the analysis.\n",
      "\n",
      "2. **Requirement for Data Classification and Risk Assessment**: The analysis includes the University of North Carolina at Chapel Hill and Northwestern University, which do emphasize risk assessments and data classification. However, the specific requirements and processes may not be accurately reflected in the analysis.\n",
      "\n",
      "3. **Mandatory Use of Approved AI Tools**: The analysis mentions several universities, including Stanford University and the University of California at Irvine, which do have guidelines regarding the use of approved AI tools. However, the details of their policies may not be fully captured in the analysis.\n",
      "\n",
      "4. **User Education and Consent Requirements**: The analysis includes institutions like the University of California, Los Angeles and Princeton University, which do emphasize user education and consent. However, the specifics of their consent requirements may not be accurately represented.\n",
      "\n",
      "5. **Prohibition of Data Sharing with Third-Party AI Vendors**: The analysis lists universities like Texas A&M University and the University of Pennsylvania, which do have policies regarding data sharing with third-party vendors. However, the details of these policies may not be fully aligned with the analysis.\n",
      "\n",
      "Overall, while the analysis captures the general themes of the policies, the specific examples and descriptions may not accurately reflect the actual policies of the listed institutions.\n",
      "TOO MANY ITERATIONS OF HALLUCINATION IDENTIFIED, REDOING ANALYSIS!\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a32618353f42ddb8abd8d9545b58e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d230390e0eb3490fb2fd1147f2d9d4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK FAILED: FAIL\n",
      "\n",
      "1. **Regular Review and Update of AI Guidelines with Stakeholder Input**: The analysis includes Princeton University, University of Texas at Austin, University of Florida, University of Michigan--Ann Arbor, and University of California, Los Angeles. However, the summaries do not explicitly confirm that these institutions engage in regular reviews with stakeholder input as described.\n",
      "\n",
      "2. **Case-by-Case Evaluation of AI Integration**: The analysis lists University of Texas at Austin, University of Maryland, and University of Southern California. The summaries do not clearly indicate that these institutions adopt a case-by-case evaluation approach as described.\n",
      "\n",
      "3. **Establishment of Task Forces or Working Groups for AI Policy Development**: The analysis includes University of Washington, Rutgers University - New Brunswick, and Georgetown University. The summaries do not confirm the establishment of task forces or working groups for AI policy development as described.\n",
      "\n",
      "4. **Integration of AI Skills into Curriculum and Assessment Guidelines**: The analysis lists University of Notre Dame, University of California, Santa Barbara, and University of Wisconsin Madison. The summaries do not explicitly confirm that these institutions integrate AI skills into their curriculum and assessment guidelines as described.\n",
      "\n",
      "5. **Continuous Dialogue and Reflection on AI Usage**: The analysis includes Massachusetts Institute of Technology, Yale University, and Brown University. The summaries do not confirm that these institutions emphasize ongoing discussions and reflections regarding AI's role in education as described.\n",
      "\n",
      "6. **Development of Explicit AI Policies Communicated to Students**: The analysis lists University of California, Davis, University of Chicago, and California Institute of Technology. The summaries do not confirm that these institutions focus on creating clear, explicit AI policies communicated to students as described.\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a93287ebdf47fe9649c0a02a059baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK FAILED: FAIL\n",
      "\n",
      "1. **University Of Notre Dame**: The analysis states that students must document their use of AI tools in an \"Assignment Appendix: AI Acknowledgement,\" which aligns with the provided summary. This part is accurate.\n",
      "   \n",
      "2. **University Of California, Davis**: The analysis claims that students must clearly indicate which parts of their work are generated by AI and which are their own. The provided summary supports this, so this part is accurate.\n",
      "\n",
      "3. **University Of Wisconsin Madison**: The analysis states that students must document their use of AI tools, which is consistent with the provided summary. This part is accurate.\n",
      "\n",
      "4. **University Of Michigan--Ann Arbor**: The analysis claims that students must document their use of AI tools throughout the course, which aligns with the provided summary. This part is accurate.\n",
      "\n",
      "5. **The University Of Texas At Austin**: The analysis states that students must document their use of AI tools by providing an appendix that includes the entire exchange with the AI. The provided summary supports this, so this part is accurate.\n",
      "\n",
      "6. **Boston University**: The analysis states that students must disclose the prompts used and acknowledge the AI tools in APA Style. The provided summary supports this, so this part is accurate.\n",
      "\n",
      "7. **University Of California, Santa Barbara**: The analysis states that students must verify and take ownership of the information produced by AI tools. The provided summary supports this, so this part is accurate.\n",
      "\n",
      "8. **University Of California, San Diego**: The analysis states that students must ensure full transparency when AI is used to generate material. The provided summary supports this, so this part is accurate.\n",
      "\n",
      "9. **Johns Hopkins University**: The analysis states that students must specify any AI-generated material they use and properly cite it. The provided summary supports this, so this part is accurate.\n",
      "\n",
      "10. **University Of Georgia**: The analysis states that students must properly document their use of AI tools and cite any output generated by these tools. The provided summary supports this, so this part is accurate.\n",
      "\n",
      "The analysis is grounded in the provided summaries, and there are no massive inaccuracies or fabrications. Therefore, the response is \"PASS.\"\n",
      "HALLUCINATION CHECK FAILED: FAIL\n",
      "\n",
      "1. **University Of Notre Dame**: The analysis states that students must document their use of AI tools in an \"Assignment Appendix: AI Acknowledgement,\" which aligns with the summary. However, the analysis does not mention the requirement for students to provide links or screenshots of their AI interactions, which is part of the summary.\n",
      "\n",
      "2. **University Of California, Davis**: The analysis claims that students must document AI contributions, which is accurate. However, it does not specify that students must adhere to guidelines for attribution, which is mentioned in the summary.\n",
      "\n",
      "3. **University Of Wisconsin Madison**: The analysis states that students must document their use of AI tools, which is correct. However, it does not mention the requirement for students to clarify uncertainties before using such tools, which is included in the summary.\n",
      "\n",
      "4. **University Of Michigan--Ann Arbor**: The analysis states that students must document their use of AI tools, which is accurate. However, it does not mention the evaluation of this documentation as part of their term grade, which is part of the summary.\n",
      "\n",
      "5. **University Of Georgia**: The analysis states that students must document their use of AI tools, which is correct. However, it does not mention the requirement for instructors to communicate their stance on AI tool usage, which is included in the summary.\n",
      "\n",
      "6. **University Of California, Santa Barbara**: The analysis states that students must verify and take ownership of the information produced by AI tools, which is accurate. However, it does not mention the requirement for instructors to develop specific policy statements about AI use in their syllabi, which is part of the summary.\n",
      "\n",
      "7. **University Of California, San Diego**: The analysis states that full transparency is required when AI is used, which is accurate. However, it does not mention the need for communicators to educate themselves about AI tools and monitor for potential pitfalls, which is included in the summary.\n",
      "\n",
      "8. **University Of California, Los Angeles**: The analysis states that students must document their use of AI in their academic work, which is accurate. However, it does not mention the emphasis on modifying assignments to promote academic integrity, which is part of the summary.\n",
      "\n",
      "9. **University Of Maryland**: The analysis states that students must credit and cite their use of AI tools, which is accurate. However, it does not mention the requirement for students to ensure that their reflections genuinely represent their personal beliefs and ideas, which is included in the summary.\n",
      "\n",
      "10. **University Of Pennsylvania**: The analysis states that users must validate the accuracy of AI-generated content, which is accurate. However, it does not mention the requirement for researchers to consult departmental standards for authorship, which is part of the summary.\n",
      "\n",
      "These discrepancies indicate that the analysis does not fully align with the summarized policies for each institution, leading to a \"FAIL\" designation.\n",
      "TOO MANY ITERATIONS OF HALLUCINATION IDENTIFIED, REDOING ANALYSIS!\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK FAILED: FAIL\n",
      "\n",
      "1. **Mandatory Citation of AI Tools**: The University of Georgia does not have a specific policy that aligns with the description provided. Instead, it emphasizes proper documentation and communication from instructors regarding AI tool usage.\n",
      "  \n",
      "2. **Disclosure of AI Usage in Assignments**: The University of California, Davis aligns with the description, but the University of California, Los Angeles does not have a clear policy that matches the requirement for students to specify which parts of their work were generated by AI.\n",
      "\n",
      "3. **Instructor-Specified AI Use Guidelines**: The examples provided for Columbia University and The Ohio State University do not fully align with the description of explicit guidelines in syllabi regarding acceptable AI use.\n",
      "\n",
      "4. **Reflection on AI Tool Usage**: The University of Southern California's policy does not explicitly require a reflective component as described.\n",
      "\n",
      "5. **Comprehensive Documentation of AI Interactions**: The University of Texas at Austin's policy does not require the level of detail described in the analysis regarding maintaining detailed documentation of interactions with AI tools.\n",
      "HALLUCINATION CHECK FAILED: FAIL\n",
      "\n",
      "1. **Mandatory Citation of AI Tools**: The example of Duke University does not align with the provided summary, which emphasizes documenting and crediting AI tool usage but does not specify a mandatory citation policy.\n",
      "  \n",
      "2. **Disclosure of AI Usage in Assignments**: The example of University of California, Davis is accurate, but the example of University of Michigan--Ann Arbor does not align with the summary, which focuses on documenting AI use throughout the course rather than just in assignments.\n",
      "\n",
      "3. **Instructor-Specified AI Use Guidelines**: The example of Columbia University is accurate, but the example of Massachusetts Institute of Technology does not align with the summary, which emphasizes an AI Acceptable Use Statement rather than general instructor guidelines.\n",
      "\n",
      "4. **Reflection on AI Tool Usage**: The example of University of Southern California is accurate, but the example of Tufts University does not align with the summary, which emphasizes documentation of AI usage rather than a reflective component.\n",
      "\n",
      "5. **Comprehensive Documentation of AI Interactions**: The example of The University of Texas at Austin is accurate, but the example of University of Illinois Urbana-Champaign does not align with the summary, which emphasizes acknowledging AI use rather than comprehensive documentation.\n",
      "TOO MANY ITERATIONS OF HALLUCINATION IDENTIFIED, REDOING ANALYSIS!\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK FAILED: FAIL\n",
      "\n",
      "1. **Documentation and Citation of AI Tool Usage**: The analysis claims that Duke University, University Of Notre Dame, University Of Michigan--Ann Arbor, University Of Georgia, and University Of California, Los Angeles have this policy. However, the summaries indicate that:\n",
      "   - Duke University requires documentation and credit for AI tool use, but does not specify the detailed requirements as described in the analysis.\n",
      "   - University Of Notre Dame requires documentation but emphasizes an \"Assignment Appendix: AI Acknowledgement,\" which is not fully aligned with the analysis.\n",
      "   - University Of Michigan--Ann Arbor requires documentation but focuses on evaluation as part of the term grade, which is not mentioned in the analysis.\n",
      "   - University Of Georgia emphasizes proper documentation and instructor communication but does not match the analysis's description of the policy.\n",
      "   - University Of California, Los Angeles emphasizes clear communication of principles and guidelines but does not specifically require detailed documentation as described.\n",
      "\n",
      "2. **Instructor Guidelines on AI Tool Usage**: The analysis lists Columbia University, Yale University, The Ohio State University, Dartmouth College, and Northwestern University. However:\n",
      "   - The summaries for these institutions do not fully align with the analysis's description of requiring clear expectations in syllabi, particularly for Dartmouth College and Northwestern University, which focus more on communication rather than explicit guidelines.\n",
      "\n",
      "3. **Comprehensive Documentation of AI Interactions**: The analysis cites University Of Southern California, University Of Texas At Austin, Tufts University, and University Of California, Santa Barbara. However:\n",
      "   - The summaries do not support the claim that these institutions require comprehensive documentation of interactions as described in the analysis.\n",
      "\n",
      "4. **Ethical Use and Validation of AI Outputs**: The analysis includes University Of California, Irvine, University Of Pennsylvania, Harvard University, and University Of California, Davis. However:\n",
      "   - The summaries do not fully support the claim that these institutions have a policy specifically focused on validating AI outputs as described.\n",
      "\n",
      "5. **Transparency in AI Contributions**: The analysis lists Brown University, University Of Rochester, Johns Hopkins University, and University Of Wisconsin Madison. However:\n",
      "   - The summaries do not fully support the claim that these institutions require clear indication of AI contributions as described in the analysis.\n",
      "\n",
      "Overall, the analysis contains significant inaccuracies regarding the policies and examples provided for each institution.\n",
      "HALLUCINATION CHECK FAILED: FAIL\n",
      "\n",
      "1. **Documentation and Citation of AI Tool Usage**: The analysis states that Duke University requires students to document and credit the use of AI tools, which aligns with the summary. However, it inaccurately includes the University of Georgia, which requires proper documentation but emphasizes the importance of transparency and trustworthiness rather than specific citation practices.\n",
      "\n",
      "2. **Instructor Guidelines on AI Tool Usage**: The analysis includes Columbia University and Yale University, which both have policies that align with the description. However, it inaccurately includes The Ohio State University, which focuses on clear communication in the syllabus but does not specifically mention instructor guidelines on AI tool usage.\n",
      "\n",
      "3. **Comprehensive Documentation of AI Interactions**: The analysis includes the University of Southern California, which requires documentation of AI use, but it inaccurately includes Tufts University, which emphasizes documentation of how AI was utilized but does not require comprehensive documentation of interactions.\n",
      "\n",
      "4. **Ethical Use and Validation of AI Outputs**: The analysis includes the University of California, Irvine and University of Pennsylvania, which align with the description. However, it inaccurately includes Harvard University, which requires acknowledgment of AI tools but does not specifically mention validation of AI outputs.\n",
      "\n",
      "5. **Transparency in AI Contributions**: The analysis includes Brown University and University of Rochester, which align with the description. However, it inaccurately includes Johns Hopkins University, which requires disclosure of AI use but does not specifically mention transparency in contributions.\n",
      "\n",
      "Overall, the analysis contains inaccuracies regarding the alignment of institutions with their actual policies.\n",
      "TOO MANY ITERATIONS OF HALLUCINATION IDENTIFIED, REDOING ANALYSIS!\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK FAILED: FAIL\n",
      "\n",
      "1. **University of Wisconsin Madison**: The analysis states that the university requires documentation and citation of AI tool use, which aligns with the provided summary. However, it does not mention the requirement for instructors to provide specific instructions on how to cite AI-generated content, which is present in the summary.\n",
      "\n",
      "2. **Duke University**: The analysis claims that students must document and credit the use of AI tools, which is accurate. However, it does not specify the requirement to include the date of interaction, which is mentioned in the summary.\n",
      "\n",
      "3. **University of Georgia**: The analysis states that students must document their use of AI tools, which is correct. However, it does not mention the emphasis on instructors discussing the importance of transparency and trustworthiness in academic work, which is included in the summary.\n",
      "\n",
      "4. **University of Maryland**: The analysis states that students must credit and cite their use of AI tools, which is accurate. However, it does not mention the requirement for students to ensure that their reflections genuinely represent their personal beliefs and ideas, which is included in the summary.\n",
      "\n",
      "5. **University of California, Santa Barbara**: The analysis states that the university requires clear communication of guidelines regarding AI use, which is accurate. However, it does not mention the requirement for students to verify and take ownership of the information produced by AI tools, which is included in the summary.\n",
      "\n",
      "6. **Princeton University**: The analysis states that students must obtain permission before using AI tools, which is accurate. However, it does not mention the requirement for students to provide an explicit statement of method, which is included in the summary.\n",
      "\n",
      "7. **Vanderbilt University**: The analysis states that faculty and students must disclose how and when AI is used, which is accurate. However, it does not mention the requirement for compliance with university policies on confidentiality and privacy, which is included in the summary.\n",
      "\n",
      "8. **University of California, Los Angeles**: The analysis states that the university emphasizes the need for clear communication of principles and guidelines regarding AI use, which is accurate. However, it does not mention the importance of modifying assignments to promote academic integrity, which is included in the summary.\n",
      "\n",
      "9. **University of California, San Diego**: The analysis states that the university requires full transparency when AI is used, which is accurate. However, it does not mention the requirement for communicators to educate themselves about AI tools and monitor for potential pitfalls, which is included in the summary.\n",
      "\n",
      "10. **University of California, Davis**: The analysis states that students must clearly indicate which parts of their work are generated by AI, which is accurate. However, it does not mention the requirement for students to adhere to guidelines for attribution when using AI tools, which is included in the summary.\n",
      "\n",
      "Overall, while the analysis captures some aspects of the policies, it fails to accurately reflect the specific requirements and nuances present in the summarized policies for several institutions.\n",
      "HALLUCINATION CHECK FAILED: FAIL\n",
      "\n",
      "1. **University of Wisconsin Madison**: The analysis states that the university requires documentation and citation of AI tool use, which aligns with the provided summary. However, the summary emphasizes that students must clarify uncertainties before using AI tools, which is not explicitly mentioned in the analysis.\n",
      "\n",
      "2. **Duke University**: The analysis claims that students must document and credit AI tool use, which is accurate. However, the summary specifies that students should include a citation detailing the query and the date it was generated, which is not reflected in the analysis.\n",
      "\n",
      "3. **University of Georgia**: The analysis states that students must document their use of AI tools, which is accurate. However, the summary emphasizes the importance of instructors discussing AI tool usage and providing support for evaluating AI-generated content, which is not mentioned in the analysis.\n",
      "\n",
      "4. **University of Maryland**: The analysis states that students must credit and cite their use of AI tools, which is accurate. However, the summary includes additional requirements for students to ensure their reflections represent their personal beliefs, which is not mentioned in the analysis.\n",
      "\n",
      "5. **Princeton University**: The analysis states that students must obtain permission before using AI tools, which is accurate. However, the summary emphasizes the need for students to disclose how these tools were used, which is not explicitly mentioned in the analysis.\n",
      "\n",
      "6. **Vanderbilt University**: The analysis states that faculty and students must disclose how and when AI is used, which is accurate. However, the summary includes additional details about compliance with university policies on confidentiality and privacy, which are not mentioned in the analysis.\n",
      "\n",
      "Overall, while the analysis captures some aspects of the policies, it fails to accurately reflect the specific requirements and nuances outlined in the provided summaries for several institutions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOO MANY ITERATIONS OF HALLUCINATION IDENTIFIED, REDOING ANALYSIS!\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK FAILED: FAIL\n",
      "\n",
      "1. **Mandatory Disclosure of AI Tool Usage**: The analysis claims that the Massachusetts Institute of Technology (MIT) requires mandatory disclosure of AI tool usage. However, the summary for MIT indicates that it requires disclosure for all academic, educational, and research-related purposes, which is broader than just mandatory disclosure in academic work.\n",
      "\n",
      "2. **Citation and Attribution Requirements**: The analysis lists the University of Maryland as an example of institutions with citation and attribution requirements. However, the summary for the University of Maryland emphasizes crediting and citing AI tools according to specific assignment directions, which may not align with the broader interpretation of citation and attribution requirements as described in the analysis.\n",
      "\n",
      "3. **Documentation of AI Interaction**: The analysis includes the University of Southern California as an example of institutions requiring documentation of AI interaction. The summary for USC specifies that students must document their use of AI by submitting prompts and outputs, which is a more specific requirement than the general documentation of AI interaction mentioned in the analysis.\n",
      "\n",
      "4. **Instructor-Led Guidelines and Expectations**: The analysis cites Columbia University as an example of institutions with instructor-led guidelines. However, the summary for Columbia emphasizes the need for instructors to communicate their expectations regarding AI tools, which may not fully capture the essence of instructor-led guidelines as described in the analysis.\n",
      "\n",
      "5. **Ethical Review and Validation of AI Outputs**: The analysis includes the University of Pennsylvania as an example of institutions requiring ethical review and validation of AI outputs. However, the summary for the University of Pennsylvania focuses on transparency and validation of AI-generated content, which may not fully align with the broader interpretation of ethical review and validation as described in the analysis.\n",
      "HALLUCINATION CHECK FAILED: FAIL\n",
      "\n",
      "1. **Mandatory Disclosure of AI Tool Usage**: The analysis cites Massachusetts Institute of Technology, Duke University, University of California, San Diego, and University of Michigan--Ann Arbor. However, the actual policies from these institutions do not align with the specific requirements outlined in the analysis. For example, the University of California, San Diego emphasizes transparency but does not specifically mandate disclosure in the same manner described.\n",
      "\n",
      "2. **Citation and Attribution Requirements**: The analysis lists University of Maryland, Johns Hopkins University, University of Georgia, and Brown University. The actual policies do not uniformly require citation and attribution as described, particularly for Johns Hopkins University, which has a more stringent approach regarding AI-generated content.\n",
      "\n",
      "3. **Documentation of AI Interaction**: The analysis includes University of Southern California, The University of Texas at Austin, University of Illinois Urbana-Champaign, and University of Notre Dame. The actual policies vary significantly, particularly for the University of Southern California, which has a more detailed documentation requirement than what is summarized.\n",
      "\n",
      "4. **Instructor-Led Guidelines and Expectations**: The analysis cites Washington University in St. Louis, University of California, Los Angeles, Columbia University, and Dartmouth College. The actual policies from these institutions do not consistently reflect the same level of instructor-led guidelines as described.\n",
      "\n",
      "5. **Ethical Review and Validation of AI Outputs**: The analysis lists Texas A&M University, University of Pennsylvania, University of California at Irvine, and University of California, Davis. The actual policies do not uniformly require validation of AI outputs as described, particularly for Texas A&M University, which focuses more on documentation of methodologies rather than validation of outputs.\n",
      "\n",
      "Overall, the discrepancies between the analysis and the actual policies indicate significant inaccuracies in the representation of the institutions' approaches to AI tool usage.\n",
      "TOO MANY ITERATIONS OF HALLUCINATION IDENTIFIED, REDOING ANALYSIS!\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af027873028c4d65bf00613828e380b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n",
      "QUALITY CHECK PASSED\n",
      "HALLUCINATION CHECK PASSED\n"
     ]
    }
   ],
   "source": [
    "analyses = {}\n",
    "for query in tqdm_notebook(list(query_answers.keys())):\n",
    "    #print(f\"Analyzing {query}\")\n",
    "    text = query_answers[query]\n",
    "    analyses[query] = list(perform_chained_analysis(query, text))\n",
    "    # Save analyses as JSON in every iteration\n",
    "    with open('analyses.json', 'w') as f:\n",
    "        json.dump(analyses, f, indent=4)\n",
    "    \n",
    "    # Delete variables to free memory\n",
    "    del text, query"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_env)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
