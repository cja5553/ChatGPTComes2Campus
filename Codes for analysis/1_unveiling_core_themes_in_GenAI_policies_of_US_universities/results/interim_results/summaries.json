{
    "Princeton University": "1. **Faculty Discretion on Generative AI Use**: Faculty members have the authority to decide whether to allow, limit, or prohibit the use of generative AI tools in their courses. Clear policies should be established and communicated in syllabi.\n\n2. **Academic Integrity Regulations**: Students must ensure that all submitted work is original and not misrepresented as their own, including outputs generated by generative AI. Violations will lead to disciplinary action.\n\n3. **Acknowledgment of AI Use**: If students receive permission to use generative AI, they must disclose its use in their assignments, following the university's guidelines on source acknowledgment.\n\n4. **Prohibition of Unauthorized AI Tutoring**: Students are not allowed to use AI tutoring bots or unauthorized tutoring services as per existing policies on outside assistance.\n\n5. **Engagement Over Detection**: The university does not recommend the use of detection tools for identifying AI-generated work, emphasizing instead the importance of discussions about academic integrity and original work.\n\n6. **Ongoing Assessment of AI Tools**: The university will continue to evaluate the implications of generative AI on teaching and learning, adapting policies and guidelines as necessary.\n\n7. **Encouragement of Critical Thinking**: Faculty are encouraged to design assignments that promote critical thinking and creativity, minimizing reliance on generative AI for basic tasks.\n\n8. **Ethical Considerations**: Faculty should discuss the ethical implications of using generative AI, including issues of equity, access, data privacy, inaccuracies, cognitive offloading, and potential biases.\n\n9. **Student Feedback and Collaboration**: The university invites feedback from students and faculty on their experiences with generative AI, fostering a collaborative approach to integrating these tools into education. \n\n10. **Resources for Faculty**: The McGraw Center for Teaching and Learning offers support for faculty in developing effective policies and assignments that incorporate generative AI responsibly.",
    "Massachusetts Institute of Technology": "1. **Citing AI Tools**: \n   - Citation practices for AI-generated content are still evolving, and users should include sufficient information to adhere to citation principles when no official guidance exists.\n   - Cite AI tools when they are used to gather information, write, edit, synthesize ideas, or manipulate data.\n\n2. **Authorship and Responsibility**: \n   - AI cannot be considered an author; users are responsible for all content produced, including AI-generated material, which must be cited appropriately.\n\n3. **Citation Style Guidance**: \n   - Various citation styles (MLA, APA, Chicago, ACS, IEEE) provide differing guidelines for citing AI-generated content, with some styles lacking formal guidelines.\n\n4. **Documentation of AI Use**: \n   - When using AI tools, document the tool name, version, date, prompts, responses, and the user\u2019s identity to maintain transparency.\n\n5. **Accuracy of AI Outputs**: \n   - Users must verify the accuracy of AI-generated information, as it may be misleading or contain copyrighted material. It is advisable to cite reputable sources that confirm AI outputs.\n\n6. **Institutional Policies**: \n   - Familiarize yourself with the specific AI use and citation policies of your institution, course, or publication to ensure compliance.\n\n7. **Citation Management Tools**: \n   - Current citation management tools do not have specific item types for AI tools; users may categorize AI-generated content under \"software\" or \"website\" until a citation style is determined.\n\n8. **Resources for Further Guidance**: \n   - Consult institutional resources and external guidelines for best practices in citing AI tools and integrating them into academic work.",
    "Harvard University": "1. **Support for Responsible Use of AI**: Harvard encourages responsible experimentation with generative AI tools while emphasizing the importance of information security, data privacy, compliance, copyright, and academic integrity.\n\n2. **Course Policies on AI**: Instructors are encouraged to include clear policies in course syllabi regarding the use of generative AI, specifying whether it is permitted, restricted, or encouraged, and ensuring students understand expectations.\n\n3. **Confidential Data Protection**: Users must not enter confidential data into publicly available generative AI tools. Only approved tools may handle Level 2 and above confidential data.\n\n4. **Content Review Responsibility**: Individuals are responsible for reviewing AI-generated content for accuracy and potential copyright issues before publication or submission.\n\n5. **Academic Integrity Compliance**: Faculty should clarify policies on AI use in academic work, and students are encouraged to seek clarification on these policies.\n\n6. **Awareness of AI-Enabled Phishing**: The use of generative AI has increased the sophistication of phishing attempts; users should remain vigilant and report suspicious communications.\n\n7. **Vendor Risk Assessment**: Any generative AI tools procured must undergo a risk assessment by Harvard\u2019s Information Security and Data Privacy office prior to use.\n\n8. **Ongoing Monitoring and Updates**: Harvard will continuously monitor developments in generative AI and update guidelines as necessary, incorporating feedback from the community.\n\n9. **Resources for Faculty**: The university provides various resources, including workshops and guidance on integrating AI into teaching and learning, as well as tools for assessing AI use in courses.\n\n10. **AI Sandbox Availability**: Harvard offers a secure AI Sandbox for faculty and students to explore generative AI tools without compromising data security, ensuring that user data will not be used for training AI models.",
    "Stanford University": "1. **Honor Code Implications**: The use of generative AI tools (e.g., ChatGPT, Bard) in academic settings is subject to the Stanford Honor Code. Unless explicitly stated by instructors, using AI for substantial completion of assignments or exams is prohibited and treated as unauthorized assistance.\n\n2. **Instructor Discretion**: Individual instructors have the authority to set specific policies regarding the use of generative AI in their courses. These policies should be clearly communicated in course syllabi.\n\n3. **Disclosure Requirement**: Students must disclose any significant use of generative AI in their work. If in doubt, they should err on the side of transparency regarding AI assistance.\n\n4. **Monitoring Developments**: The Board on Conduct Affairs (BCA) will continue to monitor the implications of generative AI tools and may update guidance as necessary.\n\n5. **Encouragement for Clarification**: Students are encouraged to seek clarification from instructors regarding the use of AI tools in their courses if they are unsure about the policies.\n\n6. **Potential for Positive Use**: While generative AI can bypass learning objectives, it also has potential applications that can enhance learning and understanding when used appropriately.\n\n7. **Best Practices for Instructors**: Instructors are advised to provide clear guidelines on AI use, including potential detection software for AI-generated content, to maintain academic integrity.\n\n8. **Community Input**: The BCA invites community members to provide feedback and suggestions regarding the evolving use of generative AI in academic contexts.",
    "Yale University": "1. Overview of Generative AI Tools:\n   - Generative AI tools, such as ChatGPT and Microsoft Copilot, have rapidly evolved and are integrated into various applications, prompting faculty to adapt teaching methods to support student learning.\n\n2. Guidance for Instructors:\n   - Instructors should clearly communicate policies regarding AI tool usage in assignments, emphasizing academic integrity and the importance of original work.\n   - Experimenting with AI tools is encouraged to understand their capabilities and limitations.\n\n3. Ethical Considerations:\n   - Faculty and students must be aware of biases and inaccuracies in AI-generated content and should verify outputs before use.\n   - Protecting confidential and sensitive information is crucial; do not input personal or proprietary data into AI tools.\n\n4. Academic Integrity Policies:\n   - Instructors are advised to update academic integrity policies to include guidelines on AI usage and attribution requirements.\n   - Students must cite any AI-generated content used in their coursework.\n\n5. Support and Resources:\n   - The Poorvu Center offers resources, workshops, and consultations to help faculty integrate AI into their teaching effectively.\n   - Yale's Clarity platform provides secure access to AI tools while safeguarding user data.\n\n6. Curriculum Development:\n   - Yale is investing in faculty positions focused on AI and offering seed grants for curriculum reviews to enhance AI-related education.\n   - Interdisciplinary collaboration is encouraged to leverage diverse expertise in AI research and application.\n\n7. Continuous Learning and Feedback:\n   - Faculty and students are encouraged to engage in ongoing discussions about AI's implications in education and research.\n   - Feedback on AI tools and practices is welcomed to improve institutional support and resources.",
    "University of Pennsylvania": "1. **Instructor Responsibility**: Each instructor at Penn is responsible for establishing their own policies regarding student use of generative AI, ensuring alignment with course learning goals.\n\n2. **Policy Communication**: Instructors should communicate their AI policies clearly and frequently, including in syllabi and during assignment introductions, to help students understand acceptable and unacceptable uses.\n\n3. **Academic Integrity**: Under Penn\u2019s Code of Academic Integrity, unauthorized assistance, including significant use of AI-generated work, is prohibited unless explicitly allowed by the instructor.\n\n4. **Assignment Design**: Instructors are encouraged to design assignments that either limit or incorporate AI use based on their educational objectives, ensuring that students engage in critical thinking and original work.\n\n5. **Transparency and Disclosure**: Users of AI must disclose when AI tools are used in creating work products and validate the accuracy of AI-generated content against trusted sources.\n\n6. **Privacy and Data Protection**: Instructors and students must avoid sharing personal or sensitive data with AI tools and ensure compliance with privacy regulations, particularly regarding patient information under HIPAA.\n\n7. **Bias and Misinformation**: Users should be aware of the potential for AI to produce biased or inaccurate content and take steps to mitigate these risks.\n\n8. **Intellectual Property Considerations**: Users must respect intellectual property rights and avoid uploading confidential information to AI platforms without proper protections in place.\n\n9. **Consultation and Support**: CETLI offers consultations for instructors to discuss AI integration into teaching, and resources are available for developing effective AI policies.\n\n10. **Ongoing Evaluation**: The rapidly evolving nature of AI technology necessitates regular updates to policies and practices to ensure they remain relevant and effective.",
    "California Institute of Technology": "1. **Guidance for Responsible Use of AI**: \n   - Caltech encourages responsible experimentation with generative AI (GenAI) and large language model (LLM) tools in research, education, and administrative work.\n   - Users must adhere to existing regulations and institute policies, including data protection and academic integrity.\n\n2. **Four Guiding Principles**:\n   - **Disclosure**: Users must disclose the use of GenAI tools to avoid misunderstandings and potential claims of academic dishonesty.\n   - **Data Protection**: Sensitive, confidential, or restricted information must not be input into open GenAI tools, as this may lead to public disclosure.\n   - **Content Responsibility**: Users should critically assess AI-generated content for accuracy, as outputs can be misleading or incorrect.\n   - **Honor Code Compliance**: The use of GenAI must align with Caltech's honor code, emphasizing fairness and ethical conduct.\n\n3. **Security and Compliance Considerations**:\n   - Caltech currently lacks contracts for most AI tools, meaning security and compliance measures are not guaranteed.\n   - Users are advised to consult Information Security for guidance on using AI tools with sensitive information.\n\n4. **Evolving Guidelines**: \n   - The guidance on AI use will evolve alongside technological advancements and regulatory changes, with updates communicated to the community.\n\n5. **Contact for Questions**: \n   - For inquiries regarding the use of AI technologies, users can reach out to gen_ai@caltech.edu.",
    "Duke University": "1. **Discretion in AI Use**: Instructors at Duke have the authority to define the use of generative AI in their courses, but unauthorized use is considered cheating under the updated Duke Community Standard.\n\n2. **Syllabus Updates Required**: Faculty are encouraged to include specific guidance on generative AI in their syllabi, reflecting their individual stance on its use.\n\n3. **Research and Understanding**: Instructors should familiarize themselves with generative AI tools and their implications before drafting policies, including understanding their strengths and limitations.\n\n4. **Rationale for Policies**: Faculty should articulate the reasoning behind their AI policies, considering the impact on students' learning and intellectual development.\n\n5. **Support AI Literacy**: Educators must help students understand how to use AI responsibly, including proper citation practices and the ethical implications of AI-generated content.\n\n6. **Defining Acceptable Use**: If allowed, instructors should clearly outline acceptable circumstances for AI use, including guidelines for revision and attribution.\n\n7. **Plagiarism and Cheating Policies**: Academic integrity policies should explicitly address the use of AI, defining consequences for unauthorized use and ensuring students understand the importance of original work.\n\n8. **AI Detection Software**: The use of AI detection software is not endorsed due to reliability issues, and any findings should initiate a conversation rather than serve as definitive proof of cheating.\n\n9. **Ethical Considerations**: Instructors should discuss the ethical implications of AI, including issues of bias, inequity, and intellectual property, to foster a deeper understanding among students.\n\n10. **Future of Education**: The integration of AI in education presents opportunities for rethinking assignments and learning outcomes, emphasizing critical thinking, collaboration, and real-world applications.",
    "Brown University": "1. **AI's Role in Academic Mission**:\n   - Brown University acknowledges the challenges and opportunities presented by generative AI tools in higher education.\n   - Ongoing discussions among academic leaders focus on aligning AI use with the university's values to enhance faculty and student success.\n\n2. **Guidelines for AI Usage**:\n   - Faculty have discretion over AI tool usage in their courses; clear communication of policies is essential.\n   - The Sheridan Center provides resources, including sample syllabus language, to assist faculty in integrating AI responsibly.\n\n3. **Academic Integrity Concerns**:\n   - Unapproved use of AI for assignments is considered a violation of Brown\u2019s Academic Code.\n   - Faculty must clarify expectations regarding AI to prevent plagiarism and ensure original work.\n\n4. **Citation and Attribution**:\n   - Students using AI tools for assignments must properly cite AI-generated content, with guidelines provided by the Library.\n\n5. **Data Protection**:\n   - Caution is advised when using AI tools that may store or share sensitive data; the Office of Information Technology offers guidance on data protection.\n\n6. **AI as a Research Tool**:\n   - AI presents both potential benefits and risks for research; resources are available to help researchers navigate these challenges.\n\n7. **Intellectual Property Considerations**:\n   - Researchers must be aware of intellectual property issues when using AI tools, with guidance provided by the Office of the Vice President for Research.\n\n8. **Community Engagement and Resources**:\n   - Brown will host discussions on AI's impact on education and society, encouraging experimentation with AI to enhance academic experiences.\n\n9. **Ethical Considerations**:\n   - Discussions around AI should include ethical issues such as authorship, data privacy, and equity in access to AI tools.\n\n10. **Support for Faculty and Students**:\n    - Various resources, including consultations and workshops, are available to support the Brown community in understanding and integrating AI effectively and ethically.",
    "Johns Hopkins University": "1. **Generative AI Tool Guidance Overview**:\n   - The guidance provides best practices for using generative AI tools in teaching, evolving with technology and community needs.\n   - Faculty should refer to divisional guidelines for discipline-specific information.\n\n2. **Definition and Benefits of Generative AI Tools**:\n   - Generative AI tools create content (text, images, etc.) using advanced algorithms.\n   - They can enhance course development, automate content creation, and provide personalized feedback to students.\n\n3. **Ethical Considerations and Bias**:\n   - Awareness of potential biases in AI outputs is crucial; biases may stem from training datasets.\n   - The importance of mitigating bias aligns with broader ethical standards in AI development.\n\n4. **Basic Principles for Using AI-Generated Content**:\n   - Use AI selectively to augment, not replace, human-generated content.\n   - Continuous validation of AI-generated content is necessary to ensure quality.\n\n5. **Guidelines for Faculty and Students**:\n   - Faculty should create clear syllabus statements regarding AI use in assignments.\n   - Students must disclose any use of AI tools in their work and understand the implications of unauthorized use.\n\n6. **Examples of Syllabus Statements**:\n   - Various instructors provide specific guidelines on acceptable AI use, emphasizing the importance of original work and proper citation of AI-generated content.\n\n7. **Encouragement for Exploration**:\n   - Faculty and instructional staff are encouraged to experiment with generative AI tools to understand their potential and limitations before classroom implementation.",
    "Northwestern University": "1. **Data Privacy and Security**: \n   - Users must not share sensitive or institutional data with generative AI tools unless validated by the university.\n   - Only non-confidential, public data (Level 1) can be uploaded to generative AI tools without prior approval.\n\n2. **Use of Approved Tools**: \n   - Northwestern recommends using Microsoft Copilot for generative AI tasks, as it provides data protection when accessed through a Northwestern account.\n   - New AI tools must undergo procurement and security reviews before use.\n\n3. **Academic Integrity**: \n   - Unauthorized use of generative AI in academic work is considered a violation of academic integrity policies.\n   - Instructors should clearly communicate expectations regarding AI use in assignments.\n\n4. **Guidelines for Instructors**: \n   - Instructors can choose to prohibit, conditionally allow, or encourage the use of generative AI in their courses.\n   - Clear syllabus statements regarding AI use are essential to avoid confusion among students.\n\n5. **Student Engagement**: \n   - Instructors are encouraged to involve students in discussions about the ethical use of generative AI and co-create classroom policies.\n   - Reflective assignments can help students critically assess their use of AI tools.\n\n6. **Critical Thinking and Media Literacy**: \n   - Students should analyze AI-generated content to develop critical thinking and media literacy skills.\n   - Discussions should focus on the strengths and limitations of AI tools in relation to course content.\n\n7. **Continuous Evaluation**: \n   - Outputs from generative AI tools should be periodically re-validated for accuracy and relevance.\n   - Instructors should remain aware of the evolving nature of AI technologies and adapt their teaching practices accordingly.\n\n8. **Intellectual Property Considerations**: \n   - Users must obtain necessary approvals before inputting original works or copyrighted materials into generative AI tools.\n   - Informed consent regarding data sharing with AI tools is essential for ethical use.\n\n9. **Support Resources**: \n   - Northwestern provides resources and guidance for both instructors and students on the responsible use of generative AI.\n   - The IT Service Desk is available for assistance with AI-related inquiries.",
    "Columbia University": "1. **Introduction to AI Tools**: \n   - Higher education is adapting to rapid technological advancements, particularly with AI tools like ChatGPT.\n   - The resource provides instructors with strategies for integrating AI tools into their teaching.\n\n2. **Understanding ChatGPT**: \n   - ChatGPT is a conversational AI model capable of generating text-based responses, assisting with writing, and providing feedback.\n   - The latest version, GPT-4, offers enhanced capabilities but also has limitations, such as sharing incorrect information and being unable to generate personal reflections.\n\n3. **Navigating AI in the Classroom**: \n   - Instructors should establish clear expectations regarding AI tool usage in their courses, fostering open discussions with students.\n   - Course policies should include digital transparency about AI tool usage and its implications for academic integrity.\n\n4. **Scaffolding Assignments**: \n   - Breaking down larger assignments into smaller tasks allows for ongoing feedback and deeper student engagement.\n   - This approach can reduce reliance on AI tools by promoting iterative learning and revision.\n\n5. **Designing Authentic Assessments**: \n   - Authentic assessments encourage students to apply course concepts to real-world situations, enhancing engagement and critical thinking.\n   - These assessments can minimize the temptation to misuse AI tools by requiring personal reflection and application of learned material.\n\n6. **Incorporating AI into Assignments**: \n   - Instructors can design assignments that utilize AI tools to develop digital literacy skills.\n   - Examples include analyzing AI-generated texts or using AI for feedback on student writing.\n\n7. **Conclusion**: \n   - The integration of AI tools in education is inevitable; thus, instructors should focus on transparent policies, effective communication, and thoughtful course design.\n   - The Center for Teaching and Learning (CTL) offers support for faculty in developing AI-inclusive teaching strategies.",
    "Cornell University": "1. **Curriculum Mapping for Generative AI**:\n   - Academic departments should assess the impact of generative AI on curricula.\n   - Key questions include desired student competencies with generative AI and the specific courses where these skills will be taught.\n\n2. **Program-Level Learning Outcomes**:\n   - Departments must affirm and potentially update program-level outcomes related to generative AI.\n   - Curriculum mapping helps identify redundancies and gaps in instruction.\n\n3. **Consultative Process**:\n   - The Center for Teaching Innovation (CTI) offers support for curriculum mapping, including consultations to establish timelines and next steps.\n\n4. **Learning Outcomes Review**:\n   - Establish a common language for discussing generative AI.\n   - Determine if a discipline-specific generative AI learning outcome is necessary.\n\n5. **Curriculum Integration**:\n   - Identify when and where students will learn about generative AI throughout their academic program.\n   - Explore opportunities for updating the curriculum to include generative AI topics.\n\n6. **Action Planning**:\n   - Develop concrete steps for curriculum revision that align with established timelines and instructional needs.\n\n7. **Faculty Engagement**:\n   - Faculty should engage in discussions about the implications of generative AI for their teaching and student learning.\n\n8. **Ongoing Evaluation**:\n   - Continuous assessment of generative AI's role in education is essential as technology evolves.\n\n9. **Resources and Support**:\n   - Faculty can access CTI resources for guidance on integrating generative AI into their teaching practices.\n\n10. **Contact Information**:\n    - For further assistance, faculty are encouraged to reach out to CTI for consultations and support.",
    "University of Chicago": "1. **Introduction of PhoenixAI**: \n   - UChicago has developed PhoenixAI, a generative AI chat service tailored for the university community, ensuring security, privacy, accessibility, and equity.\n\n2. **Data Security**: \n   - Data submitted to PhoenixAI remains within the UChicago environment and is not shared with third parties or used for AI model training.\n\n3. **GitHub Copilot Business**: \n   - Access to GitHub Copilot Business is provided for coding assistance, with data protection ensured through the university's Microsoft contract.\n\n4. **Guidelines for Using Generative AI**:\n   - **Protection of University Data**: Confidential data must not be used with public generative AI tools without prior review.\n   - **Content Accuracy and Ownership**: Users are responsible for verifying the accuracy and ownership of AI-generated content, as it may contain inaccuracies or copyrighted material.\n   - **Academic Integrity**: Instructors should consult the Chicago Center for Teaching and Learning for guidance on integrating AI tools within academic honesty policies.\n\n5. **Procuring Generative AI Tools**: \n   - Any generative AI tools that process confidential data require a security review before acquisition, regardless of cost.\n\n6. **Support and Resources**: \n   - IT Services provides support for generative AI tools, and users are encouraged to submit requests through the Self-Service Portal.\n\n7. **Syllabus Guidance for Instructors**: \n   - Instructors are encouraged to clearly communicate their policies on AI tool usage in course syllabi, including when AI is permitted and how it should be cited.\n\n8. **Ethical Considerations**: \n   - Users must critically evaluate AI outputs for accuracy and bias, and avoid using AI for personal reflections or creative assignments.\n\n9. **Workshops and Training**: \n   - Academic Technology Solutions offers workshops on integrating AI into teaching, focusing on authentic learning and academic integrity.\n\n10. **Contact Information**: \n    - For questions regarding generative AI guidelines, contact the Chief Information Officer or Chief Information Security Officer at UChicago.",
    "UC Berkeley": "1. **AI Policy Hub Overview**:\n   - The AI Policy Hub at UC Berkeley is an interdisciplinary initiative aimed at developing governance and policy frameworks for artificial intelligence.\n   - It trains graduate students to conduct research that mitigates the risks and enhances the benefits of AI technologies.\n\n2. **Mission and Vision**:\n   - The mission is to cultivate a research community focused on safe and beneficial AI.\n   - The vision promotes a future where AI fosters human connection and societal well-being, rather than exacerbating harm and inequity.\n\n3. **Research and Collaboration**:\n   - The Hub supports annual cohorts of graduate students who produce policy deliverables.\n   - Collaborates with various UC Berkeley departments and centers focused on AI governance, including the Center for Long-Term Cybersecurity and the Center for Human-Compatible AI.\n\n4. **Application Process**:\n   - Applications for the Fall 2024 \u2013 Spring 2025 cohort are currently closed, with future opportunities expected in Spring 2025.\n\n5. **Current Research Focus Areas**:\n   - Topics include privacy in AI, misinformation prevention, international cooperation on AI regulation, legal adaptations for AI, and equitable AI applications in social services.\n\n6. **Guidance for Instructors**:\n   - Instructors are encouraged to develop clear policies regarding the use of generative AI tools in their courses.\n   - Suggested practices include revising learning outcomes to incorporate AI engagement and updating course materials to reflect AI's impact on disciplines.\n\n7. **Concerns and Challenges**:\n   - Issues such as academic dishonesty, equity in access to AI tools, and the potential loss of assessment integrity are highlighted.\n   - Instructors are advised to consider the implications of AI on student assessments and adapt their methods accordingly.\n\n8. **Resources and Support**:\n   - The Hub provides resources for faculty and students on the appropriate use of AI tools, including workshops and guidance documents.\n   - Ongoing updates and community engagement are encouraged to address the evolving landscape of AI in education.\n\n9. **Ethical Considerations**:\n   - The Hub emphasizes the importance of ethical AI use, aligning with UC Berkeley\u2019s Principles of Community.\n   - Users are encouraged to participate in training and familiarize themselves with the ethical implications of AI technologies.\n\n10. **Future Directions**:\n    - The Hub aims to continuously adapt its policies and research focus in response to advancements in AI technology and its societal impacts.",
    "University of California, Los Angeles": "1. **Introduction of Generative AI**: \n   - UCLA recognizes the transformative impact of generative AI tools like ChatGPT, DALL-E, and others on education and creative fields.\n\n2. **Teaching Guidance**: \n   - Faculty are encouraged to clarify expectations regarding AI use in coursework and incorporate academic integrity policies into syllabi.\n\n3. **Academic Integrity**: \n   - The UCLA Student Conduct Code applies to AI-generated content; students must acknowledge sources or submit their own work unless otherwise specified by instructors.\n\n4. **Data Privacy and Security**: \n   - Emphasis on protecting personal data and ensuring confidentiality when using AI tools. Sensitive data should not be entered into AI systems unless cleared for specific classifications.\n\n5. **Ethical Considerations**: \n   - Regular evaluation of AI systems for bias and fairness is essential. Transparency in AI decision-making processes is encouraged.\n\n6. **Limitations and Risks**: \n   - AI-generated content may contain inaccuracies or biases. Users are responsible for critically evaluating AI outputs before use.\n\n7. **Resources and Training**: \n   - UCLA provides guides and training materials to help faculty and students effectively use AI tools while adhering to ethical standards.\n\n8. **Ongoing Development**: \n   - The university is actively piloting AI tools like Microsoft Copilot and Google Gemini, with plans for broader access and integration into academic practices.\n\n9. **Community Engagement**: \n   - UCLA encourages feedback and participation from the campus community to enhance AI resources and support systems.\n\n10. **Future of AI in Education**: \n    - AI is expected to become a standard tool in higher education, necessitating ongoing adaptation and innovation in teaching and learning practices.",
    "Rice University": "1. Definition of Generative AI:\n   - Generative AI refers to systems that produce original outputs (text, images, audio, code) based on prompts, with Language Models (LLMs) like OpenAI's GPT-4 being a key example.\n\n2. Ethical Considerations:\n   - Users must verify AI-generated responses for accuracy, as AI can produce \"hallucinations\" or erroneous content.\n   - AI systems may exhibit biases due to historical data, necessitating caution in ethical decision-making.\n   - Respect copyright by providing context for AI-derived content.\n\n3. Security and Privacy Guidelines:\n   - Do not input sensitive or confidential information into consumer-focused AI services to prevent unauthorized access.\n   - Consult the Information Security Office before licensing new AI services to ensure adequate security measures are in place.\n\n4. Commitment to Ongoing Updates:\n   - The guidelines leverage existing university policies and will be updated regularly to reflect advancements in generative AI technology.\n\n5. Impact on Teaching and Learning:\n   - AI presents both opportunities and challenges for educational engagement, prompting the need for thoughtful integration into curricula.",
    "Dartmouth College": "1. **Support for Teaching with Generative AI**:\n   - Dartmouth provides resources and support for faculty to navigate the use of generative AI in teaching.\n   - Faculty can access guides on best practices, course policies, and adapting assignments to incorporate AI.\n\n2. **Instructor Authority**:\n   - Instructors have the autonomy to permit or prohibit the use of generative AI tools in their courses based on pedagogical value.\n   - It is recommended that instructors clearly define their AI policies in course syllabi.\n\n3. **Academic Integrity**:\n   - Use of generative AI tools must adhere to Dartmouth's Academic Honor Principle, requiring acknowledgment or citation of AI contributions in student work.\n   - Students are responsible for clarifying any uncertainties regarding AI use with their instructors.\n\n4. **Data Protection and Compliance**:\n   - Dartmouth emphasizes the importance of data privacy and compliance with existing policies when using generative AI tools.\n   - Users must ensure that any AI tools used comply with Dartmouth's information security policies.\n\n5. **Ongoing Evaluation and Adaptation**:\n   - The policy acknowledges the rapidly evolving nature of generative AI and encourages continuous evaluation of its impact on teaching and learning.\n   - Resources will be regularly updated to reflect new developments and best practices in the use of generative AI in education.",
    "Vanderbilt University": "1. **Policy Overview**: \n   - AI is recognized as a valuable tool that must be used ethically and in compliance with university policies and applicable laws.\n   - Users must disclose AI usage appropriately and exercise sound judgment in its application.\n\n2. **Faculty Responsibilities**:\n   - Faculty determine the use of generative AI in courses and must communicate expectations clearly to students.\n   - If no specific guidelines are provided, students may use AI tools but must disclose their usage.\n\n3. **Academic Integrity**:\n   - Faculty must define what constitutes academic dishonesty regarding AI use.\n   - Students are responsible for understanding and adhering to the rules of engagement for AI in their courses.\n\n4. **Disclosure Requirements**:\n   - Both faculty and students must disclose AI usage in research, service work, and creative expression.\n   - Disclosure should align with university policies on confidentiality and privacy.\n\n5. **Ethical Use of AI**:\n   - AI should be used in ways that respect confidentiality and privacy.\n   - Users are responsible for the accuracy and impact of AI-generated content.\n\n6. **Guidance on AI Detection**:\n   - The university has disabled Turnitin\u2019s AI detection tool due to concerns about accuracy and privacy.\n   - Instructors are encouraged to communicate openly with students about AI use and its implications.\n\n7. **Best Practices for Students**:\n   - Students should seek clarification on AI policies from instructors and disclose AI usage in assignments.\n   - They should critically evaluate AI outputs for accuracy and relevance.\n\n8. **Mitigating Unauthorized Use**:\n   - Instructors are encouraged to localize assignments and incorporate personal reflections to deter AI misuse.\n   - Assignments should be designed to require individual thought and engagement.\n\n9. **Training and Resources**:\n   - The university offers training modules on generative AI, including prompt engineering courses.\n   - Faculty and staff are encouraged to utilize these resources for personal and professional development.\n\n10. **Future Considerations**:\n    - The university will continuously revisit and update AI guidelines as technology evolves.\n    - Faculty and students should stay informed about best practices and emerging trends in AI usage.",
    "University of Notre Dame": "1. **Purpose of Generative AI Policy**: \n   - The policy aims to guide students in using generative AI responsibly, ensuring it supplements rather than replaces genuine engagement with coursework.\n\n2. **Academic Integrity**: \n   - Misrepresentation of AI-generated work as original constitutes academic dishonesty. Violations of instructor policies regarding AI use will be treated as Honor Code violations.\n\n3. **Instructor Authority**: \n   - Faculty have the discretion to define acceptable AI use in their courses, including prohibiting or managing its use based on course objectives.\n\n4. **Transparency and Documentation**: \n   - Students must disclose AI usage in assignments, including proper citations and documentation of prompts used.\n\n5. **Educational Goals**: \n   - The policy emphasizes the importance of acquiring knowledge and skills through coursework, preparing students for future professional environments where AI will be prevalent.\n\n6. **Critical AI Literacy**: \n   - Students are encouraged to develop critical thinking skills regarding AI, understanding its limitations, biases, and ethical implications.\n\n7. **Potential Uses of AI**: \n   - AI can assist in brainstorming, summarizing complex materials, and providing personalized learning experiences, but should not replace core learning processes.\n\n8. **Ethical Considerations**: \n   - The policy highlights the need for ethical use of AI, including awareness of data privacy, intellectual property issues, and the potential for bias in AI outputs.\n\n9. **Support and Resources**: \n   - Students are encouraged to reach out to the Office of Academic Standards for clarification on AI policies and to seek guidance on responsible AI use.\n\n10. **Continuous Evaluation**: \n   - The university will regularly review and update AI policies to adapt to technological advancements and ensure alignment with educational goals.",
    "University of Michigan--Ann Arbor": "1. **Generative AI Training and Resources**:\n   - U-M offers extensive training on Generative AI (GenAI) for staff and students, including workshops and on-demand resources for prompt literacy.\n\n2. **U-M AI Tools**:\n   - Tools like U-M GPT are secure, private, and free for staff and students, ensuring that shared data is not used for model training.\n\n3. **Choosing GenAI Tools**:\n   - When selecting external GenAI tools, consider privacy risks, misleading costs, and the importance of understanding their limitations.\n\n4. **Ethical Considerations**:\n   - GenAI is not sentient and can exhibit biases; users should critically evaluate outputs and avoid reliance on AI for ethical decision-making.\n\n5. **Academic Integrity**:\n   - Students must understand that using GenAI tools requires transparency and adherence to academic integrity policies, including proper citation and documentation of AI use.\n\n6. **Guidelines for Faculty**:\n   - Instructors should clearly communicate policies regarding GenAI use in syllabi, including acceptable and prohibited uses, and engage students in discussions about AI's implications.\n\n7. **Course Design and Assessment**:\n   - Faculty are encouraged to redesign courses and assessments to incorporate GenAI, focusing on higher-order thinking and authentic learning experiences.\n\n8. **Research Implications**:\n   - GenAI can enhance research capabilities but must be used responsibly, with careful documentation and verification of outputs to mitigate biases and inaccuracies.\n\n9. **Data Privacy**:\n   - U-M prohibits the use of third-party AI tools with sensitive institutional data, emphasizing the need for compliance with privacy regulations like FERPA.\n\n10. **Continuous Adaptation**:\n    - U-M's policies on GenAI will evolve as the technology develops, requiring ongoing review and adaptation to ensure ethical and effective use in academic settings.",
    "georgetown University": "1. **Copyright and AI Tools**:\n   - U.S. copyright law regarding AI is evolving; the U.S. Copyright Office is assessing the implications of AI on copyright.\n   - Current court cases address whether generative AI tools violate copyright by using copyrighted material as training data.\n   - AI-generated content cannot be copyrighted as it lacks human authorship.\n\n2. **Plagiarism and Academic Integrity**:\n   - Using AI-generated text without citation is considered plagiarism, as it does not constitute original work.\n   - False citations generated by AI tools violate academic integrity standards.\n\n3. **Scholarly Publishing Guidelines**:\n   - Generative AI tools must be disclosed in scholarly submissions; they should not be credited as authors.\n   - Human oversight is essential in the use of AI in publishing processes.\n\n4. **Privacy Concerns**:\n   - Risks of data breaches and re-identification exist when using AI tools, especially with sensitive information.\n   - Users should avoid sharing personal data and review privacy policies of AI tools.\n\n5. **Bias in AI**:\n   - AI tools can perpetuate biases present in their training data, leading to biased outputs.\n   - Users should critically evaluate AI-generated content for potential biases.\n\n6. **Using AI in Education**:\n   - Faculty are encouraged to integrate AI tools into assignments while maintaining academic integrity.\n   - Clear policies on AI usage should be established in course syllabi to guide students.\n\n7. **Citing AI Tools**:\n   - Specific guidelines exist for citing AI-generated content in various citation styles (APA, Chicago, MLA).\n   - Users must provide prompts and context when citing AI-generated material.\n\n8. **Recommendations for Educators**:\n   - Faculty should develop clear expectations regarding AI use in assignments to foster trust and integrity.\n   - Encourage students to critically engage with AI outputs and understand their limitations.\n\n9. **Resources and Support**:\n   - Georgetown University offers resources and consultations for faculty on integrating AI into teaching and research.\n   - Workshops and guides are available to help faculty and students navigate the use of AI tools effectively.",
    "University of North Carolina at Chapel Hill": "1. **Establishment of Guidelines**: The UNC Generative AI Committee has developed guidelines for the ethical and responsible use of generative AI tools by students, faculty, and staff, recognizing the inevitability of AI integration in academic and administrative contexts.\n\n2. **Philosophy of Use**: The guiding principle is that AI should assist human thought processes rather than replace them. Users are encouraged to engage critically with AI outputs and maintain responsibility for the final product.\n\n3. **Documentation and Transparency**: Users must disclose the use of generative AI in their work, ensuring transparency in how AI tools contribute to assignments, research, and administrative tasks.\n\n4. **Limitations of Generative AI**: Users should be aware of the limitations of AI, including potential biases, inaccuracies, and intellectual property concerns. Outputs may not always be verifiable or reliable.\n\n5. **Confidentiality and Data Security**: Sensitive or personal data must not be entered into generative AI tools without prior risk assessment and approval from the university's Information Security Office.\n\n6. **Academic Integrity**: The use of generative AI must align with the university's Honor Code, and any unauthorized assistance or plagiarism is strictly prohibited.\n\n7. **Adaptability of Guidelines**: The guidelines are expected to evolve with advancements in AI technology. Instructors and researchers are encouraged to tailor these guidelines to fit their specific contexts and disciplines.\n\n8. **Encouragement of Critical Thinking**: Instructors should promote critical engagement with AI-generated content, fostering a culture of inquiry and encouraging students to question the information provided by AI tools.\n\n9. **Inclusivity and Accessibility**: AI tools should be used to enhance inclusivity and accessibility in educational and administrative settings, ensuring that outputs cater to diverse needs.\n\n10. **Continuous Learning**: Users are encouraged to stay informed about developments in AI technology and best practices, participating in professional development opportunities to enhance their understanding and integration of AI tools.",
    "Carnegie Mellon University": "1. **Academic Integrity and Generative AI**:\n   - Carnegie Mellon University (CMU) emphasizes that the use of generative AI tools, such as ChatGPT, is considered unauthorized assistance unless explicitly permitted by instructors.\n   - Students must review course syllabi for specific guidelines on AI tool usage in assignments.\n\n2. **Instructor Guidance**:\n   - Instructors are encouraged to clarify their expectations regarding AI use and to communicate these policies effectively to students.\n   - Faculty should engage students in discussions about academic integrity and the implications of using AI tools.\n\n3. **Data Privacy and Security**:\n   - Students should only enter publicly shareable information into generative AI tools, avoiding private or sensitive data.\n   - Awareness of potential phishing and security risks associated with AI tools is crucial.\n\n4. **Copyright and Ownership**:\n   - The copyright status of AI-generated content remains unclear; students should be cautious about claiming ownership of AI outputs.\n   - Modifications to AI-generated content may enhance copyright protection but should be approached carefully.\n\n5. **Accuracy and Reliability**:\n   - Generative AI tools can produce inaccurate or misleading content; students are responsible for fact-checking and verifying AI outputs before submission.\n   - Instructors should encourage critical evaluation of AI-generated material.\n\n6. **Policy Variability**:\n   - Academic integrity policies may vary by course; instructors should specify what constitutes acceptable collaboration and assistance.\n   - Students are encouraged to seek clarification from instructors regarding AI tool usage.\n\n7. **Integration of AI in Learning**:\n   - Instructors may leverage AI tools for educational purposes, such as brainstorming or generating discussion questions, while ensuring that students understand the limitations of these tools.\n   - Assignments should be designed to promote original student work and critical thinking, minimizing reliance on AI-generated content.\n\n8. **Legal Considerations**:\n   - Instructors must ensure compliance with legal guidelines, including FERPA and ADA, when using AI tools in their courses.\n   - Students should not be required to use unvetted AI tools, and alternative assignments should be provided for those who opt out.\n\n9. **Continuous Adaptation**:\n   - CMU acknowledges the evolving nature of AI technologies and encourages ongoing dialogue about their implications in academic settings.\n   - Faculty are urged to stay informed about best practices and to adapt their teaching strategies accordingly.",
    "Emory University": "1. **Purpose of AI Ethics at Emory**:\n   - Emory University emphasizes the importance of ethical considerations in AI research and applications, providing resources and guidance for both instructors and students.\n\n2. **Key Ethical Topics**:\n   - The program addresses urgent issues such as disinformation, bias, privacy, surveillance, and algorithmic colonialism, aiming to equip individuals with practical tools for ethical data usage.\n\n3. **Ethical Data and AI Groups**:\n   - Emory collaborates with various organizations focused on ethical AI, including:\n     - **AI4ALL**: Promotes diversity in AI education and policy.\n     - **Algorithmic Justice League**: Raises awareness about AI impacts and advocates for affected communities.\n     - **Data for Black Lives**: Uses data to drive change for Black communities.\n\n4. **Educational Resources**:\n   - Emory offers online courses and guides on practical data ethics, highlighting the significance of ethical frameworks in AI development and implementation.\n\n5. **Interdisciplinary Approach**:\n   - The initiative integrates research across humanities, social sciences, and data sciences to address issues like online polarization and discriminatory algorithms.\n\n6. **Community Engagement**:\n   - Emory supports community-rooted AI research and encourages diverse perspectives, including Indigenous and feminist viewpoints, to shape the future of AI technology.\n\n7. **Commitment to Inclusion**:\n   - The university promotes the empowerment of underrepresented groups in AI, ensuring that diverse voices contribute to the ethical discourse surrounding AI technologies.",
    "University of Virginia": "1. **Ethical Principles in AI Education**:\n   - The use of AI in education presents opportunities and ethical challenges, including privacy, transparency, environmental concerns, and accessibility.\n   - A comprehensive framework is proposed to guide stakeholders in developing and deploying ethical AI in education.\n\n2. **Guidelines for Responsible AI Use**:\n   - Educational stakeholders should be equipped with knowledge and skills to use AI tools ethically.\n   - Institutions are encouraged to develop policies addressing the challenges posed by AI in education.\n\n3. **Academic Integrity Concerns**:\n   - The rise of AI tools like ChatGPT raises significant concerns regarding academic honesty and plagiarism.\n   - Institutions must implement strategies to ensure ethical use and prevent academic dishonesty.\n\n4. **Incorporating AI in Teaching**:\n   - Faculty are encouraged to explore the integration of AI tools in their teaching while being mindful of ethical implications.\n   - Clear guidelines should be established regarding permissible uses of AI in coursework.\n\n5. **Privacy and Data Protection**:\n   - Many AI tools save user data, raising privacy concerns. Institutions should ensure that tools used in education protect user information.\n   - UVA's licensed tools, such as UVA Copilot Chat, provide contractual data protection.\n\n6. **Student Responsibilities**:\n   - Students must understand the limitations of AI tools and critically assess their outputs.\n   - Acknowledgment of AI tool usage in assignments is required, including how and when they were used.\n\n7. **Instructor Guidelines**:\n   - Instructors can restrict or permit AI tool usage in assignments and should communicate these policies clearly.\n   - AI should not be used for grading student work, as it may compromise the integrity of original submissions.\n\n8. **Discussion and Education**:\n   - Open discussions about AI's role in education can help shape student perspectives and promote academic integrity.\n   - Faculty should model responsible use of AI and encourage students to reflect on their educational goals.",
    "Washington University in St. Louis": "1. **Secure AI Tools**: \n   - WashU has approved specific AI tools for use with sensitive data, including HIPAA and FERPA protected information.\n   - The WashU ChatGPT Beta utilizes OpenAI\u2019s ChatGPT-4o and is compliant for sensitive data use.\n\n2. **Procuring AI Tools**: \n   - All generative AI tools must be assessed for risk by WashU\u2019s Office of Information Security before use.\n   - Users must contact WashU IT when procuring AI tools to ensure appropriate privacy and security protections.\n\n3. **Responsible Use Guidelines**: \n   - Users must not enter sensitive or confidential data into publicly available AI tools.\n   - AI-generated content should be verified for accuracy, as these tools can produce misleading or fabricated information.\n\n4. **Academic Integrity**: \n   - The use of AI tools in academic work must adhere to university policies; unauthorized use is considered a violation.\n   - Faculty should clarify AI usage policies in syllabi and assignments, and students are encouraged to seek clarification.\n\n5. **AI-Enabled Phishing Awareness**: \n   - Users should remain vigilant against AI-enhanced phishing scams and report suspicious communications.\n\n6. **Ethical Considerations**: \n   - Instructors should reflect on the ethical implications of AI use in their courses and communicate clear policies regarding AI tool usage.\n\n7. **Adaptation in Teaching**: \n   - Faculty are encouraged to explore how AI can enhance learning while also addressing potential drawbacks, such as reliance on AI for fundamental skills.\n\n8. **Transparency in AI Policies**: \n   - Instructors should clearly outline when and how AI tools can be used in their courses, including expectations for citations and evidence of work processes.\n\n9. **Continuous Learning and Adaptation**: \n   - The university is committed to evolving its AI policies and practices in response to advancements in technology and educational needs.",
    "University of California, Davis": "1. **Understanding Limitations and Bias in AI**:\n   - Recognizing the limitations of AI is crucial for scientific and ethical considerations.\n   - Bias in algorithms can lead to systematic errors in outputs, necessitating critical appraisal of AI results.\n\n2. **Framework for Evaluating AI Tools**:\n   - **Reliability**: Assess the creator's credentials and transparency.\n   - **Objective**: Understand the purpose behind the AI's creation and information sharing.\n   - **Bias**: Identify potential biases in the AI model and training data.\n   - **Ownership**: Determine the ownership of the AI tool (private, government, academic).\n   - **Type**: Analyze the machine learning model used and its training methods.\n\n3. **Importance of Critical Engagement**:\n   - Users should critically engage with AI outputs, considering their accuracy and relevance.\n   - Ethical issues surrounding AI tools must be addressed, including potential biases and ownership concerns.\n\n4. **Encouragement of Responsible AI Use**:\n   - UC Davis promotes responsible experimentation with AI tools while adhering to guidelines on data privacy, compliance, and academic integrity.\n   - Users are encouraged to verify AI-generated content before publication or sharing.\n\n5. **Ongoing Research and Development**:\n   - Research on AI's implications for teaching and learning is evolving, highlighting both opportunities and limitations.\n   - Instructors are encouraged to integrate AI literacy into their teaching practices to prepare students for future challenges.\n\n6. **Guidance for Instructors and Students**:\n   - Instructors should establish clear policies regarding AI use in coursework and communicate these to students.\n   - Students should be encouraged to use AI tools ethically and transparently, ensuring proper citation and acknowledgment of AI contributions.\n\n7. **Addressing Academic Integrity**:\n   - The use of AI tools must align with the UC Davis Code of Academic Conduct, emphasizing honesty and integrity in academic work.\n   - Policies should be developed to mitigate potential misuse of AI, including plagiarism and unauthorized assistance.\n\n8. **Resources and Support**:\n   - UC Davis provides various resources and support for both students and faculty to navigate the complexities of AI in academic settings.\n   - Continuous updates and guidance will be provided as AI technologies evolve.",
    "University of California, San Diego": "1. **Use of ChatGPT and Generative AI**:\n   - ChatGPT is a Generative AI tool that can assist in content generation but is not a substitute for academic integrity.\n   - Its use may be considered cheating if it replaces the student's own work without instructor permission.\n\n2. **Instructor Authorization**:\n   - Students must seek explicit permission from instructors to use AI tools for assignments.\n   - Silence from instructors does not imply permission; students should clarify usage guidelines.\n\n3. **Potential Risks**:\n   - Using AI tools without authorization can lead to integrity violations, including severe academic penalties.\n   - Students should be prepared to disclose AI usage to instructors if asked.\n\n4. **Guidance for Ethical Use**:\n   - AI should be used to enhance, not replace, human creativity and effort.\n   - Transparency about AI usage is crucial for maintaining trust and integrity in academic work.\n\n5. **Best Practices for AI Integration**:\n   - Review and edit AI-generated content for accuracy and bias.\n   - Avoid using AI for sensitive communications or tasks requiring nuanced understanding.\n\n6. **Resources and Support**:\n   - UC San Diego provides resources for understanding and using AI responsibly, including training and guidelines.\n   - TritonGPT is the university's preferred AI tool, ensuring data security and compliance with university policies.\n\n7. **Attribution and Copyright**:\n   - Proper attribution is required for AI-generated content, and users should be aware of copyright implications when using AI tools.\n\n8. **Future of AI at UC San Diego**:\n   - The university is committed to exploring AI's potential while ensuring ethical and responsible use in academic and administrative contexts.",
    "University of Florida": "1. **Definition of ChatGPT**: \n   - ChatGPT is a generative AI tool developed by OpenAI, utilizing natural language processing to produce conversational responses based on extensive training data.\n\n2. **Use in Higher Education**: \n   - ChatGPT can enhance teaching and learning through tutoring, content creation, brainstorming, and language translation, but it also raises concerns about academic integrity.\n\n3. **Privacy and Security Guidelines**: \n   - Sensitive or restricted data (e.g., personal information, education records) must not be input into ChatGPT due to privacy risks. Users should be aware that data shared may be publicly accessible.\n\n4. **Academic Integrity Concerns**: \n   - The ease of generating AI content increases risks of plagiarism and unauthorized assistance. Faculty must educate students on responsible AI use and proper citation practices.\n\n5. **Assessment Design Strategies**: \n   - Faculty should create assessments that minimize misuse of AI, such as using authentic tasks, clear guidelines on AI usage, and alternative formats for demonstrating understanding.\n\n6. **Limitations of ChatGPT**: \n   - ChatGPT can produce inaccurate or biased information, lacks recent knowledge, and may generate fictional references. Users must verify the accuracy of AI-generated content.\n\n7. **Detection of AI-Generated Content**: \n   - Current tools for detecting AI-generated text are unreliable and should not be solely relied upon for academic misconduct claims. Faculty are encouraged to design assessments that are resistant to AI misuse.\n\n8. **Resources and Support**: \n   - The Center for Instructional Technology and Training (CITT) offers consultations and workshops on integrating AI into teaching and learning effectively while maintaining academic integrity.",
    "University of Southern California": "1. **Purpose of the Guide**: \n   - The guide aims to assist students, professors, and researchers in understanding the use of Generative AI in academic contexts, focusing on ethical considerations and practical applications.\n\n2. **Current Policy Status**: \n   - USC lacks a universal policy on Generative AI use in academic work; individual professors set their own guidelines.\n\n3. **Academic Integrity**: \n   - Proper citation and attribution are essential when using AI-generated content. Misrepresentation of AI-generated work as one's own is a violation of academic integrity.\n\n4. **Critical Evaluation**: \n   - Users must critically assess AI-generated content for accuracy and credibility, as AI can produce plausible but incorrect information.\n\n5. **Ethical Concerns**: \n   - Issues include unknown data sources, unauthorized use of copyrighted material, lack of proper attribution, and inherent biases in AI outputs.\n\n6. **Limitations of Generative AI**: \n   - AI tools may generate fictitious information (\"hallucinations\"), lack reproducibility, and often provide outdated data due to training cutoffs.\n\n7. **Guidelines for Instructors**: \n   - Instructors are encouraged to communicate their policies clearly and can choose to embrace or discourage AI use in their courses.\n\n8. **Best Practices for AI Use**: \n   - Suggestions include using AI for brainstorming, critical evaluation of AI outputs, and requiring students to disclose AI's role in their work.\n\n9. **Detection Tools**: \n   - Tools like Turnitin and OpenAI's AI Text Classifier can help identify AI-generated content, but they are not foolproof.\n\n10. **Continuous Learning**: \n    - Instructors are encouraged to stay informed about advancements in AI to adapt their teaching methods accordingly. \n\nThis summary encapsulates the key points of the USC guide on using Generative AI in research and academic work, emphasizing the importance of ethical considerations, academic integrity, and critical evaluation.",
    "The University of Texas at Austin": "1. **Definition and Purpose of AI Tools**:\n   - AI tools enhance efficiency, automate tasks, and solve complex problems across various domains.\n   - They can uncover patterns, provide insights, and generate content, transforming workflows.\n\n2. **Responsible Use of AI**:\n   - Users must protect university data and adhere to guidelines for responsible AI usage.\n   - Familiarity with data classification levels (Public, Controlled, Confidential) is essential.\n\n3. **Types of AI Tools**:\n   - **Text-based AI Tools**: Understand and generate human-like responses (e.g., Microsoft Copilot, OpenAI ChatGPT, Google Gemini).\n   - **AI Assistants**: Enhance productivity in collaboration tools (e.g., Zoom AI, Grammarly).\n   - **Developer Tools**: API access for integrating AI into applications (e.g., Azure OpenAI, Google Vertex).\n\n4. **UT-Specific AI Initiatives**:\n   - Development of a UT-specific large language model (LLM) is underway, aimed for launch in Fall 2024.\n\n5. **Vendor Risk Assessment**:\n   - AI products must have university contracts and undergo security assessments before use with non-public data.\n   - Contact the Information Security Office for vendor risk assessments.\n\n6. **Guidelines for Classroom Use**:\n   - Instructors should clearly outline acceptable AI use in syllabi, including citation requirements.\n   - Students must disclose AI tool usage in assignments to maintain academic integrity.\n\n7. **Limitations of AI Tools**:\n   - AI tools can produce inaccurate or biased outputs (hallucinations).\n   - Users must critically evaluate AI-generated content and verify information.\n\n8. **Ethical Considerations**:\n   - Users should be aware of privacy concerns, potential biases, and the environmental impact of AI technologies.\n   - Ethical use includes understanding the implications of AI on labor and intellectual property.\n\n9. **Ongoing Education and Support**:\n   - The university provides resources and workshops to help faculty and students navigate AI tools effectively.\n   - Continuous updates to policies and guidelines will reflect advancements in AI technology.\n\n10. **Contact Information**:\n    - For questions or guidance on AI tools, contact the IT Innovation team at it.innovation@utexas.edu.",
    "Georgia Institute of Technology": "1. **Accelerated Access to AI Tools**: Georgia Tech has introduced the Microsoft Copilot Enterprise AI chat service to enhance access to generative AI tools while ensuring data protection and copyright compliance.\n\n2. **Guidance for Responsible AI Use**: The Office of Information Technology (OIT) has issued guidelines for the responsible adoption of generative AI, emphasizing data privacy, security best practices, and the importance of verifying AI-generated content.\n\n3. **Data Protection**: Users are prohibited from entering personally identifiable information (PII), protected data, or Georgia Tech organizational data into AI tools. Compliance with data privacy policies is mandatory.\n\n4. **Dos and Don'ts**: \n   - **Do** verify the accuracy of AI-generated content and disclose AI tool usage.\n   - **Don't** use unapproved AI tools or share sensitive data.\n\n5. **Ongoing Development**: The guidance will evolve as AI technology advances, with plans for additional AI services and workshops to educate the community on effective AI use.\n\n6. **Ethical Considerations**: Users must be aware of potential biases in AI outputs and the implications of using AI-generated content in research and publications, including issues of plagiarism and intellectual property.\n\n7. **Syllabus Statements**: Instructors are encouraged to include clear policies regarding the use of AI tools in their courses, emphasizing transparency and adherence to academic integrity.\n\n8. **Research Guidance**: Generative AI can assist in brainstorming and idea generation but should not replace critical thinking or the research process. Users must maintain academic integrity and disclose AI contributions in their work.\n\n9. **Future Directions**: An interdisciplinary team will explore additional AI capabilities and develop ethical frameworks for AI use at Georgia Tech, ensuring alignment with institutional values and standards.",
    "UCI": "1. **No Campuswide Policy on ChatGPT**: \n   - UCI does not have a campuswide policy on ChatGPT, similar to the absence of policies for other tools like graphing calculators.\n\n2. **Instructor Discretion on AI Use**: \n   - Students may use ChatGPT if instructors permit it and provide clear guidelines on its appropriate use aligned with learning objectives.\n\n3. **Academic Freedom and Responsibility**: \n   - Instructors are not obligated to incorporate ChatGPT but should be aware of its use by students and provide guidance to enhance decision-making.\n\n4. **Writing Process and AI**: \n   - Instructors are encouraged to teach all components of the writing process, even if some tasks can be offloaded to AI tools.\n\n5. **Comparison to Traditional Tools**: \n   - ChatGPT should not be equated with traditional tools like spellcheck; instructors must clarify expectations regarding its use.\n\n6. **Prompts and Academic Integrity**: \n   - Well-crafted prompts can reduce the likelihood of cheating, but instructors must remain vigilant as AI capabilities evolve.\n\n7. **Composition Program Policy**: \n   - The Composition Program mandates that all submitted work must be generated by students, prohibiting the use of AI for substantive portions of assignments.\n\n8. **Avoiding AI Detection Tools**: \n   - UCI advises against using generative AI detection tools due to reliability issues and potential privacy concerns.\n\n9. **Addressing Illicit AI Use**: \n   - Instructors should adjust teaching methods to minimize opportunities for misuse and provide constructive feedback on AI-generated work.\n\n10. **STEM Context**: \n    - Even in technical fields, human context is crucial; students should learn to produce original work rather than relying solely on AI.\n\n11. **Examples of AI Integration**: \n    - Various UCI instructors are experimenting with ChatGPT in their courses, using it for assignments and discussions to enhance learning.\n\n12. **Ethical Considerations**: \n    - Faculty must consider ethical implications, including data privacy, bias, and the accuracy of AI-generated content.\n\n13. **ZotGPT and UCI AI Services**: \n    - UCI offers secure AI services like ZotGPT, Microsoft Copilot, and Google Gemini, which are designed to protect user data and comply with university policies.\n\n14. **Data Protection Levels**: \n    - Different AI tools have varying data protection levels, with ZotGPT supporting up to P3",
    "New York University": "1. **Overview of AI Use at NYU**:\n   - NYU actively engages in AI and machine learning for research and experimentation.\n   - Generative AI tools, such as ChatGPT and Google Bard, are increasingly utilized across various disciplines.\n\n2. **Data Privacy and Security**:\n   - Careful consideration is required when selecting and using generative AI tools to protect privacy and data.\n   - NYU provides private instances of AI tools for community members, ensuring compliance with data privacy policies.\n\n3. **Guidelines for Student Use of AI**:\n   - Students may use AI tools only with instructor approval and must acknowledge their use.\n   - Students are responsible for the accuracy and integrity of their submissions, regardless of AI assistance.\n\n4. **Academic Integrity Policies**:\n   - Misuse of AI tools can lead to violations of NYU's Academic Integrity Policy, including plagiarism and cheating.\n   - Faculty are encouraged to clarify acceptable AI use in their courses to prevent misunderstandings.\n\n5. **Adapting Assignments**:\n   - Faculty can choose to integrate, avoid, or forbid AI use in assignments.\n   - Integrating AI encourages discussion and collaboration, while avoiding AI focuses on tasks that require human effort.\n\n6. **Detection and Adjudication of Misuse**:\n   - Identifying AI misuse is complex; faculty should document evidence and engage students in discussions about their work.\n   - NYU does not endorse AI detection tools due to high error rates and potential for false accusations.\n\n7. **Recommendations for Faculty**:\n   - Clearly communicate AI policies in syllabi and class discussions.\n   - Design assignments that promote learning and critical thinking, reducing reliance on AI.\n\n8. **Citing AI-Generated Content**:\n   - AI-generated text should not be treated as a reliable academic source; original sources should be cited instead.\n   - If AI use is permitted, instructors may require proper citation of AI-generated content.\n\n9. **Resources and Support**:\n   - NYU offers various resources for faculty and students to navigate AI use, including workshops and guidelines.\n   - Faculty can request access to NYU-licensed AI models for research and teaching purposes.\n\n10. **Future Considerations**:\n    - As AI technology evolves, NYU anticipates ongoing adaptations to policies and practices regarding AI use in academia.",
    "University of California, Santa Barbara": "1. **Data Protection Guidelines for ChatGPT Use**:\n   - Users must avoid entering personal, confidential, or sensitive information into ChatGPT, as it may not be protected.\n   - Data classified as Protection Level 3 or 4 should not be used with ChatGPT.\n\n2. **Licensing and Compliance**:\n   - UC policy mandates that software agreements ensure compliance with security and privacy practices.\n   - Currently, there is no agreement with OpenAI that provides necessary data protections, exposing users to potential data loss.\n\n3. **Personal Responsibility**:\n   - Use of ChatGPT is considered personal use without a formal agreement, placing responsibility on the individual to comply with OpenAI\u2019s Terms of Use.\n\n4. **Academic Integrity**:\n   - The UCSB Writing Program emphasizes maintaining academic integrity when using AI writing tools, requiring acknowledgment of AI assistance in academic work.\n\n5. **Guidelines for Educators**:\n   - Instructors should communicate clear expectations regarding AI use in assignments and foster discussions about the ethical implications of AI technologies.\n\n6. **Critical Engagement with AI**:\n   - Students are encouraged to critically evaluate AI-generated content, verify information, and maintain their own authorial voice while using AI tools.\n\n7. **Caution with AI Detection Tools**:\n   - AI detection tools may produce false positives and should be used cautiously; instructors should rely on diverse assessment strategies.\n\n8. **Ongoing Development of Policies**:\n   - UCSB is actively working on developing comprehensive policies regarding the use of generative AI in academic settings, with updates to be shared as they become available.",
    "University of Illinois Urbana-Champaign": "1. **Use of Generative AI in Academic Work**:\n   - Generative AI is considered unauthorized assistance in the Learning Design and Leadership (LDL) Program unless explicitly approved by the advisory committee.\n   - If approved, students must disclose the extent of AI usage in their theses or dissertations.\n\n2. **Academic Integrity and AI**:\n   - Students must adhere to the Illinois Student Code, particularly regarding academic integrity, which prohibits unauthorized assistance.\n   - Academic dishonesty, including plagiarism and fabrication, may result in severe consequences, including failing grades.\n\n3. **Documentation Requirements**:\n   - When using generative AI, students must provide prompts, output text with changes highlighted, and an analysis of their experience with the AI tool.\n\n4. **Citing AI Usage**:\n   - Students are required to cite any generative AI tools used in their work, including the tool's name, version, and the specific tasks performed with it.\n\n5. **Collaboration and Self-Plagiarism**:\n   - Students are encouraged to cite peer contributions and avoid self-plagiarism by ensuring all submitted work is original and properly referenced.\n\n6. **Reporting Violations**:\n   - Students have a responsibility to report any observed academic integrity violations, including plagiarism or inappropriate reviews.\n\n7. **Best Practices for AI Use**:\n   - Students should familiarize themselves with the benefits and limitations of generative AI, including issues like bias and inaccuracies.\n   - Ethical use of AI tools should align with the principles of responsible research conduct.\n\n8. **Training and Resources**:\n   - The university provides resources and training opportunities to support ethical AI use and academic integrity, including access to approved AI tools and guidelines.\n\n9. **Organizational Support**:\n   - The university is committed to providing consistent guidance on the ethical use of generative AI, ensuring compliance with privacy and data protection regulations.\n\n10. **Encouraging Responsible AI Literacy**:\n    - Faculty are encouraged to integrate discussions about AI ethics and responsible use into their curricula to foster a culture of integrity and critical thinking among students.",
    "UNIVERSITY of WISCONSIN\u2013MADISON": "1. **General Policy Overview**:\n   - UW\u2013Madison has established policies governing the use of generative AI tools to protect institutional data and ensure compliance with legal and ethical standards.\n   - All faculty, staff, students, and affiliates must adhere to these policies when using generative AI.\n\n2. **Prohibited Uses**:\n   - Sensitive or protected data (e.g., FERPA, HIPAA information) must not be entered into generative AI tools without appropriate internal review.\n   - Uploading unauthorized electronic files or data that could facilitate cyber scams is strictly prohibited.\n   - AI-generated code cannot be used in institutional IT systems without human verification for malicious elements.\n\n3. **Data Classification and Protection**:\n   - Institutional data must be classified according to university policies to ensure privacy and confidentiality.\n   - Users are responsible for understanding data classification and ensuring compliance with relevant policies.\n\n4. **Incident Reporting**:\n   - Any potential breaches of data protection or confidentiality must be reported by members of the UW\u2013Madison community.\n\n5. **Trustworthy AI**:\n   - Users are encouraged to select AI tools that align with the National Institute of Standards and Technology\u2019s (NIST) characteristics of trustworthy AI.\n\n6. **Academic Integrity**:\n   - Students must understand their instructors' expectations regarding the use of AI tools in coursework and are responsible for adhering to academic integrity policies.\n   - If AI tools are permitted, students must properly cite any AI-generated content.\n\n7. **Guidance for Instructors**:\n   - Instructors are encouraged to clearly communicate their policies on AI use in syllabi and throughout the course.\n   - Discussions about the implications of AI on academic integrity should be integrated into course content.\n\n8. **Resources and Support**:\n   - UW\u2013Madison provides various resources, including webinars and guides, to help faculty and students navigate the use of generative AI responsibly.\n   - For questions regarding data classification or AI policies, users can contact designated university officials. \n\n9. **Microsoft Copilot**:\n   - Microsoft Copilot is available to all UW\u2013Madison users, offering enterprise data protection. Users must avoid entering sensitive data into this tool.\n\n10. **Continuous Policy Evolution**:\n    - The university's policies on generative AI will evolve as technology and its implications for education and research develop. Regular updates and guidance will be provided to the community.",
    "Boston College": "1. **Definition and Context of AI in Research**:\n   - Generative AI tools, such as ChatGPT, are increasingly utilized in academic research for tasks like summarizing papers and brainstorming ideas.\n   - The Office of the Vice Provost for Research at Boston College provides resources to support faculty and staff in using these tools responsibly.\n\n2. **Privacy Concerns**:\n   - Information shared with generative AI tools is not private and may expose sensitive data to unauthorized parties.\n   - Users should avoid entering personally identifiable or confidential information into AI systems.\n\n3. **Bias and Discrimination**:\n   - Generative AI tools can perpetuate human biases present in their training data, leading to discriminatory outcomes.\n   - Users must be aware of potential biases in AI-generated content.\n\n4. **Accuracy and Reliability**:\n   - AI-generated content can be inaccurate or misleading, sometimes referred to as \"hallucinations.\"\n   - Researchers are responsible for verifying the accuracy of AI-generated material before use.\n\n5. **Authorship and Academic Integrity**:\n   - AI tools cannot be credited as authors; human authors must take responsibility for the content produced.\n   - Journals may require disclosure of AI usage in submitted work, and authors must ensure proper attribution of all sources.\n\n6. **IRB Considerations**:\n   - Researchers using AI tools must complete the \"Get Tech\" process to ensure compliance with security and legal requirements.\n   - Confidential participant data should not be processed using generative AI without explicit consent.\n\n7. **Grant Writing and Review**:\n   - The use of generative AI tools in grant reviews is prohibited by NIH and NSF due to confidentiality concerns.\n   - Researchers can use AI tools for drafting proposals but must be cautious about sharing sensitive information.\n\n8. **Guidelines for Use**:\n   - Faculty should establish clear policies regarding the use of AI in coursework, and students should seek clarification on allowed uses.\n   - All AI tool usage must comply with existing university policies and ethical standards.\n\n9. **Data Security**:\n   - Users should not use Boston College credentials to sign up for publicly available AI tools, as this may compromise data security.\n   - Confidential data should not be entered into any AI tool without university review.\n\n10. **Resources and Support**:\n    - Faculty and staff are encouraged to reach out to the Office of the Vice Provost for Research for guidance on AI usage in research.\n    - Additional resources are available through Boston College's Information Technology Services",
    "Rutgers University - New Brunswick": "1. **Definition of AI**: \n   - AI refers to machines performing tasks that typically require human intelligence, including reasoning and problem-solving. Generative AI specifically creates content (text, images, etc.) based on user prompts.\n\n2. **Limitations of AI**: \n   - AI can exhibit biases, produce misinformation, raise plagiarism concerns, and present challenges in accountability and ownership of generated content. Quality and reliability issues include inaccuracies and superficiality in outputs.\n\n3. **Ethical Concerns**: \n   - AI-generated content may perpetuate biases, lead to misinformation, and complicate issues of authorship and intellectual property. There are also concerns about unequal access to AI tools.\n\n4. **Data Privacy and Security**: \n   - AI tools may inadvertently expose sensitive data and collect personal information, raising privacy concerns.\n\n5. **Academic Integrity**: \n   - Rutgers' Academic Integrity Policy mandates that all submitted work must be the student's own, created without impermissible technologies. Instructors should clarify AI usage expectations in their courses.\n\n6. **AI in Teaching and Research**: \n   - AI can assist in various academic tasks, including generating research questions, summarizing literature, and aiding in data analysis. However, its use must be approached with caution due to potential ethical and accuracy issues.\n\n7. **Guidance for Instructors**: \n   - Instructors are encouraged to develop clear policies regarding AI use in their courses, emphasizing critical thinking and originality in assignments. They should also educate students on ethical AI use.\n\n8. **AI Literacy**: \n   - AI literacy involves understanding and responsibly interacting with AI technologies, including recognizing their limitations and ethical implications.\n\n9. **Publisher Policies**: \n   - Before using AI-generated content in publications, researchers should check specific publisher policies regarding attribution and permissible use.\n\n10. **Resources and Support**: \n   - Rutgers provides various resources, including workshops and guidelines, to help faculty and students navigate the challenges and opportunities presented by AI technologies.",
    "Tufts University": "1. **Support for Generative AI in Research**:\n   - Tufts University encourages the use of generative AI tools for various research applications, including data processing, text generation, transcription, qualitative data analysis, literature reviews, study material generation, translation, and optical character recognition.\n\n2. **Consultation Services**:\n   - Research Technology offers consultations for faculty and students in areas such as bioinformatics, data science, and digital humanities to effectively integrate generative AI into their research workflows.\n\n3. **Guidelines for Use**:\n   - Users must protect confidential data and avoid entering sensitive information into generative AI tools.\n   - AI-generated content should be reviewed for accuracy, as AI can produce misleading or incorrect information.\n\n4. **Academic Integrity**:\n   - The use of generative AI must adhere to existing academic integrity policies. Faculty should clarify acceptable uses of AI in their courses, and students are encouraged to seek guidance on these policies.\n\n5. **Procurement of AI Tools**:\n   - Faculty and staff must consult with Technology Services (TTS) before procuring generative AI tools to ensure compliance with privacy and security standards.\n\n6. **Risks and Costs**:\n   - Users should be aware of potential risks associated with generative AI, including data privacy concerns, intellectual property issues, and the possibility of AI-generated content being inaccurate or biased.\n\n7. **Training and Resources**:\n   - Tufts provides training and resources for faculty and staff to effectively utilize generative AI tools, including workshops and online guides.\n\n8. **Ongoing Evaluation**:\n   - The university will continuously monitor developments in generative AI and update guidelines as necessary to reflect best practices and emerging technologies.",
    "University of Washington": "1. **Expectations of Academic Integrity**:\n   - UW students must uphold high standards of academic and professional honesty.\n   - Understanding specific expectations regarding academic standards, especially concerning technology use, is crucial.\n\n2. **Use of AI Tools**:\n   - AI content generators (e.g., ChatGPT) can enhance learning but may violate academic standards if used without instructor permission.\n   - Cheating includes unauthorized assistance from technology in assignments or exams.\n\n3. **Instructor Guidelines**:\n   - Students should read course syllabi to understand individual instructor expectations regarding AI use.\n   - If uncertain, students are encouraged to seek clarification before utilizing AI resources.\n\n4. **Types of Academic Misconduct**:\n   - Academic misconduct includes cheating, falsification, plagiarism, unauthorized collaboration, and submitting the same work for different courses without permission.\n\n5. **Reporting Misconduct**:\n   - Instructors suspecting academic misconduct must report it to the Community Standards & Student Conduct (CSSC).\n\n6. **Resources for Support**:\n   - UW offers various academic support programs, including writing tools, citation resources, and library services to assist students in maintaining academic integrity.\n\n7. **Commitment to Integrity**:\n   - The UW community emphasizes the importance of honesty, trust, and responsibility in academic pursuits, fostering a culture of integrity.",
    "Boston University": "1. **AI and Academic Integrity Concerns**:\n   - The use of AI tools in higher education raises complex issues regarding academic integrity, particularly in relation to cheating, plagiarism, and data misrepresentation.\n   - Boston University (BU) is reviewing its Academic Conduct Code to address AI-related concerns.\n\n2. **Instructor Responsibilities**:\n   - Faculty must clearly communicate their expectations regarding AI use in their courses, including defining acceptable and unacceptable uses.\n   - Instructors are encouraged to create syllabus statements outlining AI usage guidelines and to discuss these with students.\n\n3. **Proposed Syllabus Statements**:\n   - Instructors can choose from various approaches to AI use, including:\n     - **Use with Prior Permission**: AI tools allowed only for specific assignments.\n     - **Use Freely Permitted with Acknowledgment**: AI use allowed with proper citation.\n     - **Use Freely Permitted without Acknowledgment**: AI use allowed without citation requirements.\n     - **Use Prohibited**: AI use is not allowed in the course.\n\n4. **Limitations of AI Tools**:\n   - Faculty should inform students about the limitations of AI, including potential biases and inaccuracies in generated content.\n   - Privacy concerns related to AI tools should also be addressed, with alternative assessments offered for students wary of sharing personal information.\n\n5. **Ongoing Development of AI Policies**:\n   - BU is in the process of developing comprehensive policies regarding AI use in education, with input from faculty and ongoing discussions about best practices.\n   - The Boston University AI Task Force is tasked with assessing AI's role in education and making recommendations for its effective and ethical use.",
    "The Ohio State University": "1. **Integration of AI in Teaching**:\n   - The Drake Institute acknowledges the rapid evolution of generative AI tools like ChatGPT and their implications for teaching and learning.\n   - AI presents both opportunities and challenges that require instructors to adapt their teaching strategies.\n\n2. **Evidence-Based Instruction**:\n   - Instructors are encouraged to rely on evidence-based approaches when integrating AI into their courses.\n   - A backward design approach is recommended to align course goals with AI applications effectively.\n\n3. **Active Learning Strategies**:\n   - Active learning methods should be employed to engage students with AI tools, promoting motivation and equity.\n   - Instructors should plan activities that scaffold learning and incorporate AI in a way that enhances student understanding.\n\n4. **Transparency in Assignments**:\n   - Clear expectations regarding AI use should be communicated in syllabi and assignment guidelines.\n   - The Transparency in Learning and Teaching (TILT) framework can be utilized to clarify the purpose, task, and criteria for success in assignments involving AI.\n\n5. **Academic Integrity**:\n   - Generative AI tools should not be used in course assignments unless explicitly authorized by the instructor.\n   - Instructors must discuss the ethical implications of AI and ensure students understand academic integrity policies related to AI use.\n\n6. **Evaluation and Reflection**:\n   - Instructors are encouraged to evaluate the impact of AI on student learning through both summative and formative assessments.\n   - Collecting mid-course feedback from students can provide insights into the effectiveness of AI integration in teaching.\n\n7. **Collaborative Support**:\n   - The Drake Institute and other university departments offer resources and consultations to help instructors navigate AI's impact on education.\n   - Collaboration among various university units is essential to address the complexities of AI in teaching.\n\n8. **Ongoing Adaptation**:\n   - As AI technology continues to evolve, instructors must remain adaptable and open to revising their teaching practices.\n   - Continuous professional development and engagement with emerging AI tools are encouraged to enhance instructional effectiveness.",
    "Purdue University--Main Campus": "1. **AI Integration in Course Syllabi**:\n   - Instructors are encouraged to update syllabi to clarify expectations regarding AI use.\n   - Students should understand the limitations of AI tools, including their potential to fabricate information.\n\n2. **Documentation and Transparency**:\n   - Any use of AI-generated content must be documented, and students are responsible for their learning.\n   - Clear guidelines should be established for allowable AI use in assignments, including specific restrictions.\n\n3. **Academic Integrity**:\n   - Emphasis on academic honesty, with clear communication about unauthorized AI use.\n   - Instructors should discuss the implications of AI on academic integrity and provide guidance on proper attribution.\n\n4. **Assessment Modifications**:\n   - Learning outcomes may need to be reconsidered to focus on critical thinking and application rather than rote recall.\n   - Incorporating reflective practices and relevance to students' lives can enhance engagement and motivation.\n\n5. **AI Detection Tools**:\n   - Current AI detection tools have high false-positive rates; instructors should approach results with caution.\n   - Clear procedures for addressing suspected unauthorized AI use should be outlined in the syllabus.\n\n6. **Copyright and Privacy Considerations**:\n   - Instructors must inform students about the prohibition of sharing copyrighted materials with AI tools.\n   - Compliance with FERPA is essential, ensuring student data privacy when using AI tools.\n\n7. **Collaborative Learning**:\n   - Encourage student involvement in discussions about AI use and its implications for their learning.\n   - Foster a classroom environment that promotes inquiry and critical evaluation of AI-generated content.",
    "UNIVERSITY OF MARYLAND": "1. **Integration of AI in Education**: \n   - UMD acknowledges the productivity benefits and pedagogical challenges posed by AI technologies, particularly Large Language Models (LLMs) like ChatGPT.\n   - Faculty are encouraged to adapt instructional approaches to leverage AI while addressing potential misuse and academic integrity concerns.\n\n2. **Encouragement for Faculty Engagement**: \n   - Instructors are urged to familiarize themselves with AI tools and engage in discussions about their implications for teaching and learning.\n   - The Teaching and Learning Transformation Center (TLTC) offers resources, workshops, and consultations to support faculty in integrating AI effectively.\n\n3. **Guidelines for Responsible AI Use**: \n   - Faculty should communicate clear expectations regarding AI usage in coursework, including permissible and prohibited applications.\n   - Students are encouraged to seek guidance from instructors on appropriate AI use and to verify information generated by AI tools.\n\n4. **Ethical Considerations**: \n   - Faculty and students must be aware of privacy risks, biases, and inaccuracies associated with AI tools.\n   - Discussions about the ethical implications of AI use should be integrated into the curriculum to foster responsible usage.\n\n5. **Support for Diverse Learning Needs**: \n   - Instructors should provide alternative options for students who may not be comfortable using AI tools or who face accessibility challenges.\n   - The policy emphasizes the importance of maintaining academic integrity while allowing for innovative uses of AI in assignments.\n\n6. **Continuous Adaptation and Learning**: \n   - UMD recognizes that AI is an evolving field, and ongoing adaptation to new technologies is essential for effective teaching and learning.\n   - Faculty are encouraged to experiment with AI tools to understand their benefits and limitations better.",
    "Lehigh University": "1. **Overview of Academic Integrity and Community Standards**:\n   - The presentation aims to foster discussions between faculty and students about academic integrity.\n   - It includes the Student Senate\u2019s \u201cStatement on Academic Integrity,\u201d the University\u2019s syllabus statement, and ten vignettes based on recent cases.\n\n2. **Student Senate Statement on Academic Integrity**:\n   - Students are expected to uphold high principles of personal, moral, and ethical conduct.\n   - Both students and faculty share the responsibility for promoting academic integrity.\n\n3. **Vignettes for Discussion**:\n   - Real-life scenarios are provided to prompt reflection on academic integrity issues, including plagiarism and unauthorized assistance.\n\n4. **Consequences of Academic Dishonesty**:\n   - Various vignettes illustrate the consequences of academic dishonesty, including disciplinary warnings, probation, and required completion of an Academic Integrity Seminar.\n\n5. **Use of Generative AI**:\n   - Generative AI tools are considered unauthorized assistance unless explicitly permitted by instructors.\n   - Students must disclose the extent of AI usage if approved by their advisory committee.\n\n6. **Guidance on AI Usage**:\n   - Faculty are encouraged to provide clear guidelines on the acceptable use of AI tools in coursework.\n   - Students should verify with instructors regarding the use of AI for assignments.\n\n7. **Data Protection and Compliance**:\n   - Institutional data must not be submitted to generative AI tools due to privacy and compliance concerns.\n   - Faculty and students must adhere to existing policies regarding data protection.\n\n8. **Encouragement of Responsible Exploration**:\n   - Lehigh promotes responsible experimentation with AI tools while being mindful of their limitations and risks.\n   - Faculty and students are encouraged to engage in discussions about the ethical implications of AI.\n\n9. **Resources and Support**:\n   - LTS staff are available to assist with the integration of AI tools in teaching and research.\n   - Faculty and students can access various AI tools through Lehigh accounts for enhanced data protection.\n\n10. **Continuous Learning and Adaptation**:\n    - The university encourages ongoing education about AI through seminars, workshops, and resources to stay informed about emerging trends and tools.",
    "Texas A&M University": "1. **Integration of Generative AI in Education**:\n   - Texas A&M University recognizes the potential of Generative AI to enhance learning and prepare students for future professional environments.\n   - The university aims to incorporate ethical and intentional use of AI tools into the curriculum.\n\n2. **Guidance for Faculty**:\n   - Faculty are encouraged to explore Generative AI's applications in course design, grading, and student communication.\n   - Resources and workshops are available to assist faculty in integrating AI into their teaching practices.\n\n3. **Syllabus Considerations**:\n   - Faculty should clearly communicate their stance on AI use in course syllabi, including permissible and prohibited uses.\n   - Suggested syllabus statements outline expectations regarding AI tools, emphasizing academic integrity and proper attribution.\n\n4. **Best Practices for Research**:\n   - The university has established best practices for using Generative AI in research, focusing on ethical considerations, transparency, and accountability.\n   - Researchers are encouraged to document methodologies and disclose AI usage in publications.\n\n5. **Data Privacy and Security**:\n   - AI tools must not process confidential or sensitive personal information.\n   - The university implements security measures to protect data and mitigate risks associated with AI technologies.\n\n6. **Training and Resources**:\n   - Ongoing training opportunities are provided for faculty and students to enhance AI literacy and responsible use.\n   - The university promotes interdisciplinary collaboration to address the societal implications of AI.\n\n7. **Compliance and Legal Considerations**:\n   - Researchers and faculty must adhere to intellectual property laws and ethical guidelines when using AI.\n   - The university emphasizes the importance of understanding data ownership and control in AI applications.\n\n8. **Monitoring and Evaluation**:\n   - Continuous assessment of AI tools and practices is encouraged to ensure compliance with university policies and ethical standards.\n   - Feedback mechanisms are established to address concerns related to AI use in academic and research settings.",
    "University of Georgia": "1. **Definition of Generative AI**: \n   - Generative AI (GAI) utilizes machine learning to create original content (text, images, audio) based on learned patterns from training data.\n\n2. **Opportunities and Challenges**: \n   - GAI tools present both new teaching opportunities and challenges, necessitating clear communication with students about their appropriate use in coursework.\n\n3. **Limitations of GAI**: \n   - GAI tools can produce unreliable outputs, exhibit biases, and make it difficult to trace information sources. Ethical concerns regarding privacy and intellectual property are also noted.\n\n4. **Instructor Guidance**: \n   - Instructors should engage students in discussions about academic honesty and set clear expectations regarding GAI use in their courses.\n\n5. **Course Policies on GAI**: \n   - Instructors can establish varying levels of permissiveness regarding GAI use, from highly permissive to strictly prohibited, and should communicate these policies clearly.\n\n6. **Turnitin AI Writing Detector**: \n   - UGA utilizes Turnitin\u2019s AI Writing Detector to identify AI-generated content, with specific requirements for submissions and caution regarding false positives.\n\n7. **ChatGPT Specific Guidance**: \n   - Instructors are encouraged to discuss the limitations of ChatGPT, including its inability to access current information and potential for fabricating references.\n\n8. **Educational Engagement with GAI**: \n   - Instructors may incorporate GAI tools as part of the learning process, encouraging students to analyze and critique AI-generated content.\n\n9. **Resources for Instructors**: \n   - A variety of resources are available to help instructors understand and effectively integrate GAI tools into their teaching practices.",
    "University of Rochester": "1. **Comprehensive AI Resource**: The University of Rochester Medical Center provides a guide on AI applications, innovations, and academic pursuits, covering neural networks, machine learning, and large language models.\n\n2. **AI Tool Evaluation**: An AI Tool Evaluation Checklist is available to assess the suitability and risks of AI tools, emphasizing the importance of transparency and structured documentation for machine learning datasets.\n\n3. **Ethical Guidelines**: Researchers must disclose the use of large language models (LLMs) in their work, ensuring that generated content is checked by domain experts and not used to fabricate data.\n\n4. **Generative AI Usage Restrictions**: Generative AI tools should not be used for confidential or proprietary information, and only low-risk data should be entered into these tools. The university currently has no agreements with AI providers for handling non-public data.\n\n5. **Content Creation Guidelines**: Outputs from generative AI must be edited for originality and accuracy, and should not be published verbatim. Content derived from AI may not be copyrightable, and users are responsible for any intellectual property infringements.\n\n6. **Disclosure Requirements**: When using AI-generated content, appropriate disclosures must be made, indicating the extent of AI involvement in the creation process.\n\n7. **Prohibition in Peer Review**: NIH and NSF policies prohibit the use of generative AI in peer review processes, highlighting the risks of confidentiality breaches when uploading sensitive information to non-approved AI tools.\n\n8. **Continuous Updates**: The university's guidelines on AI will be regularly updated to reflect advancements in technology and regulatory changes, ensuring compliance with institutional and state policies."
}